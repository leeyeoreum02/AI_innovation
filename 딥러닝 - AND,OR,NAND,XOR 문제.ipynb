{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, x_data, t_data, i_node, h_node, o_node, lr, iter_count):\n",
    "        if x_data.ndim == 1:    # vector\n",
    "            self.x_data = x_data.reshape((len(x_data)//i_node), i_node)\n",
    "            self.t_data = t_data.reshape((len(t_data)//o_node), o_node)\n",
    "        elif x_data.ndim == 2:  # matrix\n",
    "            self.x_data = x_data\n",
    "            self.t_data = t_data\n",
    "\n",
    "        self.learning_rate = lr\n",
    "        self.iteration_count = iter_count\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h_node)\n",
    "        self.b2 = np.random.rand(1)\n",
    "        \n",
    "        self.W3 = np.random.rand(h_node, o_node)\n",
    "        self.b3 = np.random.rand(1)\n",
    "        \n",
    "        print(\"LogicGate Object is created.\\n\")\n",
    "        \n",
    "    def __feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "\n",
    "    def __loss_val(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.__feed_forward()\n",
    "        \n",
    "        print(\"Initial loss value = \", self.__loss_val(), '\\n')\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "\n",
    "        for step in range(self.iteration_count):\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "            \n",
    "            if step % (int)(0.05*self.iteration_count) == 0:\n",
    "                print(\"step = \", step, \" : \", \"loss value = \", self.__loss_val())\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        z2 = np.dot(test_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        \n",
    "        if a3 >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "    \n",
    "        return y, result\n",
    "    \n",
    "    def accuracy(self, test_data):\n",
    "        input_data = test_data[ :, 0:-1]\n",
    "        target_data = test_data[ :, -1:]\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "            \n",
    "            (real_val, logical_val) = self.predict(input_data[index])\n",
    "            \n",
    "            if logical_val == target_data[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = len(matched_list) / len(input_data)\n",
    "        \n",
    "        return accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogicGate Object is created.\n",
      "\n",
      "Initial loss value =  1.7877206619070942 \n",
      "\n",
      "step =  0  :  loss value =  1.6592097253357312\n",
      "step =  5  :  loss value =  1.2709148721500998\n",
      "step =  10  :  loss value =  1.1150083716180754\n",
      "step =  15  :  loss value =  1.0505689766120812\n",
      "step =  20  :  loss value =  1.0223596882886479\n",
      "step =  25  :  loss value =  1.0091295936755613\n",
      "step =  30  :  loss value =  1.0023648899841537\n",
      "step =  35  :  loss value =  0.9984917401873284\n",
      "step =  40  :  loss value =  0.9959501068642351\n",
      "step =  45  :  loss value =  0.9940381155796207\n",
      "step =  50  :  loss value =  0.9924325122103983\n",
      "step =  55  :  loss value =  0.9909814420796069\n",
      "step =  60  :  loss value =  0.989612082933921\n",
      "step =  65  :  loss value =  0.9882885192257447\n",
      "step =  70  :  loss value =  0.9869922110620084\n",
      "step =  75  :  loss value =  0.9857128340478569\n",
      "step =  80  :  loss value =  0.9844439496960229\n",
      "step =  85  :  loss value =  0.9831809489653032\n",
      "step =  90  :  loss value =  0.9819200727641988\n",
      "step =  95  :  loss value =  0.9806579447828297\n",
      "step =  100  :  loss value =  0.9793913484963245\n",
      "\n",
      "Elapsed Time =>  0:00:00.167551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata = np.array([1, 1, 0, 1, 1, 0, 0, 0])\n",
    "tdata = np.array([1, 0, 0, 0])\n",
    "\n",
    "AND_obj = LogicGate(xdata, tdata, 2, 3, 1, 1e-1, 101)\n",
    "\n",
    "AND_obj.train()\n",
    "\n",
    "AND_obj.accuracy(np.array([[1, 1, 1], [0, 1, 0], [1, 0, 0], [0, 0, 0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
