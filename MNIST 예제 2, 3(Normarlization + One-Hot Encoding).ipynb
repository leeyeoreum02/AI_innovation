{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Test:\n",
    "    def __init__(self, i_node, h_node, o_node, lr):\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h_node)\n",
    "        self.b2 = np.random.rand(1)\n",
    "        \n",
    "        self.W3 = np.random.rand(h_node, o_node)\n",
    "        self.b3 = np.random.rand(1)\n",
    "        \n",
    "        print(\"========== Diabetes Object is created. ==========\\n\")\n",
    "        \n",
    "    def feed_forward(self, x_data, t_data):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "    \n",
    "    def train(self, x_data, t_data):\n",
    "        self.x_data = x_data\n",
    "        self.t_data = t_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward(self.x_data, self.t_data)\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        z2 = np.dot(test_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        predicted_num = np.argmax(a3)\n",
    "        \n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_xdata)):\n",
    "            predicted_num = self.predict(test_xdata[index])\n",
    "            \n",
    "            if predicted_num == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = len(matched_list) / len(test_xdata)\n",
    "        \n",
    "        return accuracy_val\n",
    "    \n",
    "    def display_lossval_trend(self, loss_val_list, lr, epoch):\n",
    "        plt.title('Loss Value Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(loss_val_list, ls='--', lw=2, label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "        plt.title('Training / Validation Accuracy Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(training_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.plot(validation_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration] loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n",
      "training_input_data.shape =  (60000, 784) , training_target_data.shape =  (60000, 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "    print(\"training_data.shape = \", training_data.shape)\n",
    "    \n",
    "    training_input_data = training_data[ : ,  1:]\n",
    "    training_target_data = training_data[ : , [0]]\n",
    "    \n",
    "    print(\"training_input_data.shape = \", training_input_data.shape, \", training_target_data.shape = \", training_target_data.shape)\n",
    "    \n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "index =  0 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  2000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  4000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  6000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  8000 , target_data =  [0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  10000 , target_data =  [0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  12000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  14000 , target_data =  [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  16000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      "==================================================================================\n",
      "index =  18000 , target_data =  [0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  20000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  22000 , target_data =  [0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  24000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      "==================================================================================\n",
      "index =  26000 , target_data =  [0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  28000 , target_data =  [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  30000 , target_data =  [0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  32000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      "==================================================================================\n",
      "index =  34000 , target_data =  [0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  36000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99]\n",
      "==================================================================================\n",
      "index =  38000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      "==================================================================================\n",
      "index =  40000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  42000 , target_data =  [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  44000 , target_data =  [0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  46000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99]\n",
      "==================================================================================\n",
      "index =  48000 , target_data =  [0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  50000 , target_data =  [0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  52000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  54000 , target_data =  [0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  56000 , target_data =  [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      "==================================================================================\n",
      "index =  58000 , target_data =  [0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(training_input_data)):\n",
    "    max_val = np.max(training_input_data)\n",
    "    min_val = np.min(training_input_data)\n",
    "    \n",
    "    input_data = ((((training_input_data[index] - min_val) / (max_val - min_val)) * 0.99) + 0.01)\n",
    "    \n",
    "    target_data = np.zeros(10) + 0.01\n",
    "    target_data[int(training_target_data[index, 0])] = 0.99\n",
    "    \n",
    "    if index % 2000 == 0:\n",
    "        print('==================================================================================')\n",
    "        print('index = ', index,', target_data = ', target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Diabetes Object is created. ==========\n",
      "\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "\n",
      "=========================================================\n",
      "epochs =  0  :  loss value =  0.24321070489537916 \n",
      "\n",
      "epochs =  0  :  training accuracy =  0.0\n",
      "=========================================================\n",
      "\n",
      "Elapsed Time =>  1:05:18.714243\n"
     ]
    }
   ],
   "source": [
    "i_node = training_data.shape[1] - 1\n",
    "h_node = 1\n",
    "o_node = 10\n",
    "lr = 1e-1\n",
    "epoch = 1\n",
    "\n",
    "obj1 = MNIST_Test(i_node, h_node, o_node, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\\n\")\n",
    "\n",
    "#training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "#accuracy(self, test_xdata, test_tdata\n",
    "\n",
    "loss_val_list = []\n",
    "training_acc_list = []\n",
    "validation_acc_list = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epoch):\n",
    "    for index in range(len(training_data)):\n",
    "        \n",
    "        obj1.train(input_data, target_data)\n",
    "        \n",
    "    if step % 1 == 0:\n",
    "        cur_loss_val = obj1.loss_val()\n",
    "        print(\"=========================================================\")\n",
    "        print(\"epochs = \", step, \" : \", \"loss value = \", obj1.loss_val(), '\\n')\n",
    "\n",
    "        training_accuracy = obj1.accuracy(training_data[:, 0:-1], training_data[:, -1])\n",
    "        print(\"epochs = \", step, \" : \", \"training accuracy = \", training_accuracy)\n",
    "        \n",
    "        loss_val_list.append(cur_loss_val)\n",
    "        training_acc_list.append(training_accuracy)\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj1.display_lossval_trend(loss_val_list, lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'test_data' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_input_data = test_data[:, 0:-1]\n",
    "    test_target_data = test_data[:, [-1]]\n",
    "\n",
    "    accuracy_ret = obj1.accuracy(test_input_data, test_target_data)\n",
    "    \n",
    "    print('Accuracy => ', accuracy_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
