{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtSjPwtD7mliHePel4ae02"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"64TAeZAoM_OA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1599284151172,"user_tz":-540,"elapsed":2282,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}},"outputId":"d02bf762-bb8b-4020-d61f-56e7e20ff968"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tn6tGzVGNFD4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":653},"executionInfo":{"status":"ok","timestamp":1599284158339,"user_tz":-540,"elapsed":9436,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}},"outputId":"9a846607-e74e-44e1-eaf8-52280eac9071"},"source":["import tensorflow as tf\n","from tensorflow.examples.tutorials.mnist import input_data\n","import numpy as np\n","from datetime import datetime\n","\n","\n","mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n","\n","print()\n","print(\"train.num = \", mnist.train.num_examples)\n","print(\"test.num = \", mnist.test.num_examples)\n","print(\"validation_num = \", mnist.validation.num_examples)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-146c2c6b42db>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","\n","train.num =  55000\n","test.num =  10000\n","validation_num =  5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQ1_eGjLNqzV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158340,"user_tz":-540,"elapsed":9425,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["learning_rate = 1e-3\n","epochs = 30\n","batch_size = 100"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kh-O9gv-Nz9L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158341,"user_tz":-540,"elapsed":9418,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["X = tf.placeholder(tf.float32, [None, 784])\n","\n","T = tf.placeholder(tf.float32, [None, 10])\n","\n","A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpMFqApHODcn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158342,"user_tz":-540,"elapsed":9415,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["W2 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n","b2 = tf.Variable(tf.random_normal([32]))\n","\n","C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n","\n","Z2 = tf.nn.relu(C2 + b2)\n","\n","A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"TUOKobRNPCVt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158343,"user_tz":-540,"elapsed":9410,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLx2giRIOqrz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158344,"user_tz":-540,"elapsed":9406,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["W3 = tf.Variable(tf.random_normal([14*14*32, 10], stddev=0.01))\n","b3 = tf.Variable(tf.random_normal([10]))\n","\n","Z3 = logits = tf.matmul(A2_flat, W3) + b3\n","\n","y = A3 = tf.nn.softmax(Z3)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"J6PtLey7O7_1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158344,"user_tz":-540,"elapsed":9402,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=T))\n","\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n","\n","train = optimizer.minimize(loss)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtCpOphIPcw_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284158345,"user_tz":-540,"elapsed":9399,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":["predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n","\n","accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMVsurGJPzJF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599284213637,"user_tz":-540,"elapsed":64680,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}},"outputId":"622a984b-b74a-49ef-a150-24549bf6d518"},"source":["with tf.Session() as sess:\n","  \n","  sess.run(tf.global_variables_initializer())\n","\n","  start_time = datetime.now()\n","\n","  for i in range(epochs):\n","\n","    total_batch = int(mnist.train.num_examples / batch_size)\n","\n","    for step in range(total_batch):\n","\n","      batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n","\n","      loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})\n","\n","      if step % 100 == 0:\n","        print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)\n","\n","  end_time = datetime.now()\n","\n","  print(\"\\nelapsed time = \", end_time - start_time)\n","\n","  test_x_data = mnist.test.images\n","  test_t_data = mnist.test.labels\n","\n","  accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n","\n","  print(\"\\nAccuracy = \", accuracy_val)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["epochs =  0 , step =  0 , loss_val =  2.573794\n","epochs =  0 , step =  100 , loss_val =  2.3034754\n","epochs =  0 , step =  200 , loss_val =  2.2905657\n","epochs =  0 , step =  300 , loss_val =  2.312753\n","epochs =  0 , step =  400 , loss_val =  2.3122075\n","epochs =  0 , step =  500 , loss_val =  2.3166413\n","epochs =  1 , step =  0 , loss_val =  2.3059878\n","epochs =  1 , step =  100 , loss_val =  2.2959015\n","epochs =  1 , step =  200 , loss_val =  2.2974374\n","epochs =  1 , step =  300 , loss_val =  2.2773042\n","epochs =  1 , step =  400 , loss_val =  2.284634\n","epochs =  1 , step =  500 , loss_val =  2.2909753\n","epochs =  2 , step =  0 , loss_val =  2.2872968\n","epochs =  2 , step =  100 , loss_val =  2.2746356\n","epochs =  2 , step =  200 , loss_val =  2.2599916\n","epochs =  2 , step =  300 , loss_val =  2.2366755\n","epochs =  2 , step =  400 , loss_val =  2.208164\n","epochs =  2 , step =  500 , loss_val =  2.178358\n","epochs =  3 , step =  0 , loss_val =  2.1779218\n","epochs =  3 , step =  100 , loss_val =  2.138677\n","epochs =  3 , step =  200 , loss_val =  2.0520961\n","epochs =  3 , step =  300 , loss_val =  2.0477219\n","epochs =  3 , step =  400 , loss_val =  1.9361218\n","epochs =  3 , step =  500 , loss_val =  1.7669015\n","epochs =  4 , step =  0 , loss_val =  1.7431139\n","epochs =  4 , step =  100 , loss_val =  1.6478472\n","epochs =  4 , step =  200 , loss_val =  1.5052795\n","epochs =  4 , step =  300 , loss_val =  1.4311999\n","epochs =  4 , step =  400 , loss_val =  1.17318\n","epochs =  4 , step =  500 , loss_val =  1.2032009\n","epochs =  5 , step =  0 , loss_val =  1.1162142\n","epochs =  5 , step =  100 , loss_val =  1.0929073\n","epochs =  5 , step =  200 , loss_val =  0.9551377\n","epochs =  5 , step =  300 , loss_val =  0.8649862\n","epochs =  5 , step =  400 , loss_val =  0.7853522\n","epochs =  5 , step =  500 , loss_val =  0.9513604\n","epochs =  6 , step =  0 , loss_val =  0.7575926\n","epochs =  6 , step =  100 , loss_val =  0.68239427\n","epochs =  6 , step =  200 , loss_val =  0.70739836\n","epochs =  6 , step =  300 , loss_val =  0.6217868\n","epochs =  6 , step =  400 , loss_val =  0.7545333\n","epochs =  6 , step =  500 , loss_val =  0.5511321\n","epochs =  7 , step =  0 , loss_val =  0.6245025\n","epochs =  7 , step =  100 , loss_val =  0.6753232\n","epochs =  7 , step =  200 , loss_val =  0.5235908\n","epochs =  7 , step =  300 , loss_val =  0.54976445\n","epochs =  7 , step =  400 , loss_val =  0.635541\n","epochs =  7 , step =  500 , loss_val =  0.42622265\n","epochs =  8 , step =  0 , loss_val =  0.50735015\n","epochs =  8 , step =  100 , loss_val =  0.5516362\n","epochs =  8 , step =  200 , loss_val =  0.56824476\n","epochs =  8 , step =  300 , loss_val =  0.4367729\n","epochs =  8 , step =  400 , loss_val =  0.6057726\n","epochs =  8 , step =  500 , loss_val =  0.46099225\n","epochs =  9 , step =  0 , loss_val =  0.44500887\n","epochs =  9 , step =  100 , loss_val =  0.5224344\n","epochs =  9 , step =  200 , loss_val =  0.4863629\n","epochs =  9 , step =  300 , loss_val =  0.37179732\n","epochs =  9 , step =  400 , loss_val =  0.41248667\n","epochs =  9 , step =  500 , loss_val =  0.37584642\n","epochs =  10 , step =  0 , loss_val =  0.5500381\n","epochs =  10 , step =  100 , loss_val =  0.5290494\n","epochs =  10 , step =  200 , loss_val =  0.54814416\n","epochs =  10 , step =  300 , loss_val =  0.26287615\n","epochs =  10 , step =  400 , loss_val =  0.291992\n","epochs =  10 , step =  500 , loss_val =  0.48212022\n","epochs =  11 , step =  0 , loss_val =  0.49714047\n","epochs =  11 , step =  100 , loss_val =  0.3033148\n","epochs =  11 , step =  200 , loss_val =  0.7226906\n","epochs =  11 , step =  300 , loss_val =  0.40598476\n","epochs =  11 , step =  400 , loss_val =  0.39450064\n","epochs =  11 , step =  500 , loss_val =  0.36580154\n","epochs =  12 , step =  0 , loss_val =  0.413938\n","epochs =  12 , step =  100 , loss_val =  0.3837415\n","epochs =  12 , step =  200 , loss_val =  0.47217014\n","epochs =  12 , step =  300 , loss_val =  0.47122288\n","epochs =  12 , step =  400 , loss_val =  0.4005543\n","epochs =  12 , step =  500 , loss_val =  0.36148593\n","epochs =  13 , step =  0 , loss_val =  0.36371067\n","epochs =  13 , step =  100 , loss_val =  0.27995324\n","epochs =  13 , step =  200 , loss_val =  0.42954826\n","epochs =  13 , step =  300 , loss_val =  0.28117833\n","epochs =  13 , step =  400 , loss_val =  0.46737832\n","epochs =  13 , step =  500 , loss_val =  0.43615842\n","epochs =  14 , step =  0 , loss_val =  0.31452054\n","epochs =  14 , step =  100 , loss_val =  0.40014523\n","epochs =  14 , step =  200 , loss_val =  0.25965393\n","epochs =  14 , step =  300 , loss_val =  0.27617484\n","epochs =  14 , step =  400 , loss_val =  0.58177847\n","epochs =  14 , step =  500 , loss_val =  0.4882458\n","epochs =  15 , step =  0 , loss_val =  0.35507682\n","epochs =  15 , step =  100 , loss_val =  0.30707982\n","epochs =  15 , step =  200 , loss_val =  0.24823081\n","epochs =  15 , step =  300 , loss_val =  0.3792284\n","epochs =  15 , step =  400 , loss_val =  0.53579956\n","epochs =  15 , step =  500 , loss_val =  0.34881234\n","epochs =  16 , step =  0 , loss_val =  0.5152915\n","epochs =  16 , step =  100 , loss_val =  0.50062525\n","epochs =  16 , step =  200 , loss_val =  0.44598675\n","epochs =  16 , step =  300 , loss_val =  0.37966076\n","epochs =  16 , step =  400 , loss_val =  0.340313\n","epochs =  16 , step =  500 , loss_val =  0.38375965\n","epochs =  17 , step =  0 , loss_val =  0.33596084\n","epochs =  17 , step =  100 , loss_val =  0.32528892\n","epochs =  17 , step =  200 , loss_val =  0.29123917\n","epochs =  17 , step =  300 , loss_val =  0.33435196\n","epochs =  17 , step =  400 , loss_val =  0.32971668\n","epochs =  17 , step =  500 , loss_val =  0.49412736\n","epochs =  18 , step =  0 , loss_val =  0.27238813\n","epochs =  18 , step =  100 , loss_val =  0.2564242\n","epochs =  18 , step =  200 , loss_val =  0.40293962\n","epochs =  18 , step =  300 , loss_val =  0.4353479\n","epochs =  18 , step =  400 , loss_val =  0.25085175\n","epochs =  18 , step =  500 , loss_val =  0.4362551\n","epochs =  19 , step =  0 , loss_val =  0.35274547\n","epochs =  19 , step =  100 , loss_val =  0.26618737\n","epochs =  19 , step =  200 , loss_val =  0.4070941\n","epochs =  19 , step =  300 , loss_val =  0.42171454\n","epochs =  19 , step =  400 , loss_val =  0.27441338\n","epochs =  19 , step =  500 , loss_val =  0.1869487\n","epochs =  20 , step =  0 , loss_val =  0.32765293\n","epochs =  20 , step =  100 , loss_val =  0.27983716\n","epochs =  20 , step =  200 , loss_val =  0.30693772\n","epochs =  20 , step =  300 , loss_val =  0.3129224\n","epochs =  20 , step =  400 , loss_val =  0.25225723\n","epochs =  20 , step =  500 , loss_val =  0.41266128\n","epochs =  21 , step =  0 , loss_val =  0.3198703\n","epochs =  21 , step =  100 , loss_val =  0.43396747\n","epochs =  21 , step =  200 , loss_val =  0.35148194\n","epochs =  21 , step =  300 , loss_val =  0.24559246\n","epochs =  21 , step =  400 , loss_val =  0.2722047\n","epochs =  21 , step =  500 , loss_val =  0.27831894\n","epochs =  22 , step =  0 , loss_val =  0.30337918\n","epochs =  22 , step =  100 , loss_val =  0.27620485\n","epochs =  22 , step =  200 , loss_val =  0.49991074\n","epochs =  22 , step =  300 , loss_val =  0.29002556\n","epochs =  22 , step =  400 , loss_val =  0.27359116\n","epochs =  22 , step =  500 , loss_val =  0.37388104\n","epochs =  23 , step =  0 , loss_val =  0.3084284\n","epochs =  23 , step =  100 , loss_val =  0.3042549\n","epochs =  23 , step =  200 , loss_val =  0.25588644\n","epochs =  23 , step =  300 , loss_val =  0.31081906\n","epochs =  23 , step =  400 , loss_val =  0.39227852\n","epochs =  23 , step =  500 , loss_val =  0.34501222\n","epochs =  24 , step =  0 , loss_val =  0.36370894\n","epochs =  24 , step =  100 , loss_val =  0.466766\n","epochs =  24 , step =  200 , loss_val =  0.23724747\n","epochs =  24 , step =  300 , loss_val =  0.46328422\n","epochs =  24 , step =  400 , loss_val =  0.32635263\n","epochs =  24 , step =  500 , loss_val =  0.2154812\n","epochs =  25 , step =  0 , loss_val =  0.46044254\n","epochs =  25 , step =  100 , loss_val =  0.30317742\n","epochs =  25 , step =  200 , loss_val =  0.4370339\n","epochs =  25 , step =  300 , loss_val =  0.33675158\n","epochs =  25 , step =  400 , loss_val =  0.30484632\n","epochs =  25 , step =  500 , loss_val =  0.2904898\n","epochs =  26 , step =  0 , loss_val =  0.3815828\n","epochs =  26 , step =  100 , loss_val =  0.2792155\n","epochs =  26 , step =  200 , loss_val =  0.32673672\n","epochs =  26 , step =  300 , loss_val =  0.28621608\n","epochs =  26 , step =  400 , loss_val =  0.30821157\n","epochs =  26 , step =  500 , loss_val =  0.40135252\n","epochs =  27 , step =  0 , loss_val =  0.2867554\n","epochs =  27 , step =  100 , loss_val =  0.2844901\n","epochs =  27 , step =  200 , loss_val =  0.36860648\n","epochs =  27 , step =  300 , loss_val =  0.438787\n","epochs =  27 , step =  400 , loss_val =  0.30220628\n","epochs =  27 , step =  500 , loss_val =  0.35053524\n","epochs =  28 , step =  0 , loss_val =  0.3676019\n","epochs =  28 , step =  100 , loss_val =  0.45148087\n","epochs =  28 , step =  200 , loss_val =  0.24642208\n","epochs =  28 , step =  300 , loss_val =  0.34931117\n","epochs =  28 , step =  400 , loss_val =  0.2963625\n","epochs =  28 , step =  500 , loss_val =  0.4838668\n","epochs =  29 , step =  0 , loss_val =  0.28575602\n","epochs =  29 , step =  100 , loss_val =  0.21397924\n","epochs =  29 , step =  200 , loss_val =  0.31370425\n","epochs =  29 , step =  300 , loss_val =  0.20784502\n","epochs =  29 , step =  400 , loss_val =  0.33823928\n","epochs =  29 , step =  500 , loss_val =  0.339532\n","\n","elapsed time =  0:00:46.570703\n","\n","Accuracy =  0.9109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qDxvtllJQ2sU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599284213645,"user_tz":-540,"elapsed":64682,"user":{"displayName":"이여름","photoUrl":"","userId":"14067031428196197530"}}},"source":[""],"execution_count":10,"outputs":[]}]}