{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # 은닉층 가중치  W2 = (784 X 100) Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # 출력층 가중치는 W3 = (100X10)  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        self.b3 = np.random.rand(self.output_nodes)      \n",
    "                        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 정의 (모두 행렬로 표시)\n",
    "        self.Z3 = np.zeros([1,output_nodes])\n",
    "        self.A3 = np.zeros([1,output_nodes])\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 정의 (모두 행렬로 표시)\n",
    "        self.Z2 = np.zeros([1,hidden_nodes])\n",
    "        self.A2 = np.zeros([1,hidden_nodes])\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 정의 (모두 행렬로 표시)\n",
    "        self.Z1 = np.zeros([1,input_nodes])    \n",
    "        self.A1 = np.zeros([1,input_nodes])       \n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def feed_forward(self):  \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # cross entropy \n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "        \n",
    "        # 입력층 선형회귀 값 Z1, 출력값 A1 계산\n",
    "        self.Z1 = self.input_data\n",
    "        self.A1 = self.input_data\n",
    "        \n",
    "        # 은닉층 선형회귀 값 Z2, 출력값 A2 계산    \n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = sigmoid(self.Z2)\n",
    "        \n",
    "        # 출력층 선형회귀 값 Z3, 출력값 A3 계산\n",
    "        self.Z3 = np.dot(self.A2, self.W3) + self.b3\n",
    "        self.A3 = sigmoid(self.Z3)\n",
    "        \n",
    "        # cross entropy\n",
    "        return  -np.sum( self.target_data*np.log(self.A3 + delta) + (1-self.target_data)*np.log((1 - self.A3)+delta ) )\n",
    "   \n",
    "    \n",
    "    # 정확도 측정함수 \n",
    "    def accuracy(self, test_input_data, test_target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        \n",
    "        for index in range(len(test_input_data)):\n",
    "                        \n",
    "            label = int(test_target_data[index])\n",
    "                        \n",
    "            # one-hot encoding을 위한 데이터 정규화 (data normalize)\n",
    "            data = (test_input_data[index] / 255.0 * 0.99) + 0.01\n",
    "                  \n",
    "            # predict 를 위해서 vector 을 matrix 로 변환하여 인수로 넘겨줌\n",
    "            predicted_num = self.predict(np.array(data, ndmin=2)) \n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                not_matched_list.append(index)\n",
    "        \n",
    "        accuracy_val = (len(matched_list)/(len(test_input_data)))\n",
    "        \n",
    "        return accuracy_val, not_matched_list\n",
    "    \n",
    "    \n",
    "    def train(self, input_data, target_data):   # input_data : 784 개, target_data : 10개\n",
    "        \n",
    "        self.target_data = target_data    \n",
    "        self.input_data = input_data\n",
    "        \n",
    "        # 먼저 feed forward 를 통해서 최종 출력값과 이를 바탕으로 현재의 에러 값 계산\n",
    "        loss_val = self.feed_forward()\n",
    "        \n",
    "        # 출력층 loss 인 loss_3 구함\n",
    "        loss_3 = (self.A3-self.target_data) * self.A3 * (1-self.A3)\n",
    "        \n",
    "        # 출력층 가중치 W3, 출력층 바이어스 b3 업데이트\n",
    "        self.W3 = self.W3 - self.learning_rate * np.dot(self.A2.T, loss_3)   \n",
    "        \n",
    "        self.b3 = self.b3 - self.learning_rate * loss_3  \n",
    "        \n",
    "        # 은닉층 loss 인 loss_2 구함        \n",
    "        loss_2 = np.dot(loss_3, self.W3.T) * self.A2 * (1-self.A2)\n",
    "        \n",
    "        # 은닉층 가중치 W2, 은닉층 바이어스 b2 업데이트\n",
    "        self.W2 = self.W2 - self.learning_rate * np.dot(self.A1.T, loss_2)   \n",
    "        \n",
    "        self.b2 = self.b2 - self.learning_rate * loss_2\n",
    "        \n",
    "        \n",
    "    def predict(self, input_data):        # input_data 는 행렬로 입력됨 즉, (1, 784) shape 을 가짐        \n",
    "        \n",
    "        Z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        A2 = sigmoid(Z2)\n",
    "        \n",
    "        Z3 = np.dot(A2, self.W3) + self.b3\n",
    "        A3 = sigmoid(Z3)\n",
    "        \n",
    "        predicted_num = np.argmax(A3)\n",
    "    \n",
    "        return predicted_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration]  loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration]  loaded_data.shape =  (60000, 785)\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of original data =  0.0 , count =  60000\n",
      "[DataGeneration] unique number of original data =  0.0 , ratio =  100.0  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of training data =  0.0 , count =  36000\n",
      "[DataGeneration] unique number of training data =  0.0 , ratio =  100.0  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of test data =  0.0 , count =  24000\n",
      "[DataGeneration] unique number of test data =  0.0 , ratio =  100.0  %\n",
      "=======================================================================================================\n",
      "================================================\n",
      "training data.shape =  (36000, 785)\n",
      "test data.shape =  (24000, 785)\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "test_seperation_rate = 0.4 # 테스트 데이터 분리비율\n",
    "\n",
    "try:\n",
    "\n",
    "    data_obj = DataGeneration('../mnist_train.csv', test_seperation_rate)\n",
    "\n",
    "    (training_data, test_data) = data_obj.generate()\n",
    "\n",
    "    print('================================================')\n",
    "    print('training data.shape = ', training_data.shape)\n",
    "    print('test data.shape = ', test_data.shape)\n",
    "    print('================================================')\n",
    "    \n",
    "except Exception as err:\n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , current loss_val =  7.726685105739293\n",
      "epochs =  0 , step =  1000 , current loss_val =  2.4146371274136853\n",
      "epochs =  0 , step =  2000 , current loss_val =  1.6747981168837784\n",
      "epochs =  0 , step =  3000 , current loss_val =  0.7781547232314878\n",
      "epochs =  0 , step =  4000 , current loss_val =  1.043392265260004\n",
      "epochs =  0 , step =  5000 , current loss_val =  0.7918201334576362\n",
      "epochs =  0 , step =  6000 , current loss_val =  0.9039843288195127\n",
      "epochs =  0 , step =  7000 , current loss_val =  0.7047256512942853\n",
      "epochs =  0 , step =  8000 , current loss_val =  1.231569009493784\n",
      "epochs =  0 , step =  9000 , current loss_val =  0.9102126017888018\n",
      "epochs =  0 , step =  10000 , current loss_val =  1.236673043809909\n",
      "epochs =  0 , step =  11000 , current loss_val =  0.6623947892895701\n",
      "epochs =  0 , step =  12000 , current loss_val =  0.7494383754944386\n",
      "epochs =  0 , step =  13000 , current loss_val =  0.8460913712161628\n",
      "epochs =  0 , step =  14000 , current loss_val =  0.8819393799748814\n",
      "epochs =  0 , step =  15000 , current loss_val =  0.6911768756182743\n",
      "epochs =  0 , step =  16000 , current loss_val =  1.8578894909054677\n",
      "epochs =  0 , step =  17000 , current loss_val =  1.9212285001447469\n",
      "epochs =  0 , step =  18000 , current loss_val =  0.9691373788064244\n",
      "epochs =  0 , step =  19000 , current loss_val =  0.7814950622867525\n",
      "epochs =  0 , step =  20000 , current loss_val =  1.018286287317284\n",
      "epochs =  0 , step =  21000 , current loss_val =  0.9520439608308691\n",
      "epochs =  0 , step =  22000 , current loss_val =  0.8458782978988892\n",
      "epochs =  0 , step =  23000 , current loss_val =  1.1408838019208136\n",
      "epochs =  0 , step =  24000 , current loss_val =  0.6565356111050864\n",
      "epochs =  0 , step =  25000 , current loss_val =  0.6889865796190915\n",
      "epochs =  0 , step =  26000 , current loss_val =  0.8942011979941618\n",
      "epochs =  0 , step =  27000 , current loss_val =  0.7058791580421127\n",
      "epochs =  0 , step =  28000 , current loss_val =  0.8577300836948415\n",
      "epochs =  0 , step =  29000 , current loss_val =  1.1491530310904423\n",
      "epochs =  0 , step =  30000 , current loss_val =  0.7409509786025571\n",
      "epochs =  0 , step =  31000 , current loss_val =  0.8148531224122868\n",
      "epochs =  0 , step =  32000 , current loss_val =  0.9494799024690134\n",
      "epochs =  0 , step =  33000 , current loss_val =  0.7515182095301338\n",
      "epochs =  0 , step =  34000 , current loss_val =  0.7818499912588418\n",
      "epochs =  0 , step =  35000 , current loss_val =  0.7803702633926052\n",
      "epochs =  1 , step =  0 , current loss_val =  0.7893585589145748\n",
      "epochs =  1 , step =  1000 , current loss_val =  0.7809202674248725\n",
      "epochs =  1 , step =  2000 , current loss_val =  0.7611503711689136\n",
      "epochs =  1 , step =  3000 , current loss_val =  0.8062053032806764\n",
      "epochs =  1 , step =  4000 , current loss_val =  0.7691106382248645\n",
      "epochs =  1 , step =  5000 , current loss_val =  1.0150207989660116\n",
      "epochs =  1 , step =  6000 , current loss_val =  0.7306157720801391\n",
      "epochs =  1 , step =  7000 , current loss_val =  0.8145998685995339\n",
      "epochs =  1 , step =  8000 , current loss_val =  0.9751740001909143\n",
      "epochs =  1 , step =  9000 , current loss_val =  0.8515664893100264\n",
      "epochs =  1 , step =  10000 , current loss_val =  0.7203752915714114\n",
      "epochs =  1 , step =  11000 , current loss_val =  0.728473903555903\n",
      "epochs =  1 , step =  12000 , current loss_val =  0.8174108308885266\n",
      "epochs =  1 , step =  13000 , current loss_val =  0.7495275356739382\n",
      "epochs =  1 , step =  14000 , current loss_val =  0.8354212288164744\n",
      "epochs =  1 , step =  15000 , current loss_val =  0.720449747010159\n",
      "epochs =  1 , step =  16000 , current loss_val =  0.7271296658273718\n",
      "epochs =  1 , step =  17000 , current loss_val =  1.2390713433368128\n",
      "epochs =  1 , step =  18000 , current loss_val =  1.0017636283431042\n",
      "epochs =  1 , step =  19000 , current loss_val =  0.8303490641479631\n",
      "epochs =  1 , step =  20000 , current loss_val =  0.9066369328976084\n",
      "epochs =  1 , step =  21000 , current loss_val =  0.8508208556323713\n",
      "epochs =  1 , step =  22000 , current loss_val =  0.8231694212276766\n",
      "epochs =  1 , step =  23000 , current loss_val =  1.0434665154739577\n",
      "epochs =  1 , step =  24000 , current loss_val =  0.7222309818592374\n",
      "epochs =  1 , step =  25000 , current loss_val =  0.7282431999485784\n",
      "epochs =  1 , step =  26000 , current loss_val =  0.8307825091691252\n",
      "epochs =  1 , step =  27000 , current loss_val =  0.8045170860693436\n",
      "epochs =  1 , step =  28000 , current loss_val =  0.877018956809199\n",
      "epochs =  1 , step =  29000 , current loss_val =  1.1417417806250911\n",
      "epochs =  1 , step =  30000 , current loss_val =  0.7566888223453041\n",
      "epochs =  1 , step =  31000 , current loss_val =  0.821192373440403\n",
      "epochs =  1 , step =  32000 , current loss_val =  0.7681783756022087\n",
      "epochs =  1 , step =  33000 , current loss_val =  0.8074420578544762\n",
      "epochs =  1 , step =  34000 , current loss_val =  0.8598980842992271\n",
      "epochs =  1 , step =  35000 , current loss_val =  0.8555902350793282\n",
      "epochs =  2 , step =  0 , current loss_val =  0.8191291894914912\n",
      "epochs =  2 , step =  1000 , current loss_val =  0.8288770999657734\n",
      "epochs =  2 , step =  2000 , current loss_val =  0.8071150550850035\n",
      "epochs =  2 , step =  3000 , current loss_val =  0.8204507037673298\n",
      "epochs =  2 , step =  4000 , current loss_val =  0.7386978004535888\n",
      "epochs =  2 , step =  5000 , current loss_val =  1.0459396743902472\n",
      "epochs =  2 , step =  6000 , current loss_val =  0.762036931614493\n",
      "epochs =  2 , step =  7000 , current loss_val =  0.8561648854168205\n",
      "epochs =  2 , step =  8000 , current loss_val =  0.8942390912339137\n",
      "epochs =  2 , step =  9000 , current loss_val =  0.8212948788347847\n",
      "epochs =  2 , step =  10000 , current loss_val =  0.695767283698142\n",
      "epochs =  2 , step =  11000 , current loss_val =  0.7579548663866003\n",
      "epochs =  2 , step =  12000 , current loss_val =  0.8452532366452535\n",
      "epochs =  2 , step =  13000 , current loss_val =  0.759516074182166\n",
      "epochs =  2 , step =  14000 , current loss_val =  0.8506127247657777\n",
      "epochs =  2 , step =  15000 , current loss_val =  0.7390798727099016\n",
      "epochs =  2 , step =  16000 , current loss_val =  0.707530587068761\n",
      "epochs =  2 , step =  17000 , current loss_val =  1.0516475991536827\n",
      "epochs =  2 , step =  18000 , current loss_val =  0.9368384899102049\n",
      "epochs =  2 , step =  19000 , current loss_val =  0.8400709428133162\n",
      "epochs =  2 , step =  20000 , current loss_val =  0.925162799444926\n",
      "epochs =  2 , step =  21000 , current loss_val =  0.8707554684434826\n",
      "epochs =  2 , step =  22000 , current loss_val =  0.8325346549627207\n",
      "epochs =  2 , step =  23000 , current loss_val =  0.9653592878139751\n",
      "epochs =  2 , step =  24000 , current loss_val =  0.7506179742464334\n",
      "epochs =  2 , step =  25000 , current loss_val =  0.7473582838362001\n",
      "epochs =  2 , step =  26000 , current loss_val =  0.7778446807468684\n",
      "epochs =  2 , step =  27000 , current loss_val =  0.883044814962119\n",
      "epochs =  2 , step =  28000 , current loss_val =  0.8466831898051068\n",
      "epochs =  2 , step =  29000 , current loss_val =  1.0713305016239898\n",
      "epochs =  2 , step =  30000 , current loss_val =  0.7814276253695546\n",
      "epochs =  2 , step =  31000 , current loss_val =  0.785265618987113\n",
      "epochs =  2 , step =  32000 , current loss_val =  0.7120330722444516\n",
      "epochs =  2 , step =  33000 , current loss_val =  0.8365628595039188\n",
      "epochs =  2 , step =  34000 , current loss_val =  0.9053234462717012\n",
      "epochs =  2 , step =  35000 , current loss_val =  0.8883995901858428\n",
      "epochs =  3 , step =  0 , current loss_val =  0.824501364638625\n",
      "epochs =  3 , step =  1000 , current loss_val =  0.8433722783195043\n",
      "epochs =  3 , step =  2000 , current loss_val =  0.7778601990086862\n",
      "epochs =  3 , step =  3000 , current loss_val =  0.8218225374590238\n",
      "epochs =  3 , step =  4000 , current loss_val =  0.7011493603367133\n",
      "epochs =  3 , step =  5000 , current loss_val =  1.0480393724584611\n",
      "epochs =  3 , step =  6000 , current loss_val =  0.8093456057872285\n",
      "epochs =  3 , step =  7000 , current loss_val =  0.8857109512673739\n",
      "epochs =  3 , step =  8000 , current loss_val =  0.8529430524178573\n",
      "epochs =  3 , step =  9000 , current loss_val =  0.8206970671909689\n",
      "epochs =  3 , step =  10000 , current loss_val =  0.6941490114133493\n",
      "epochs =  3 , step =  11000 , current loss_val =  0.782682714410288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  3 , step =  12000 , current loss_val =  0.867732190128416\n",
      "epochs =  3 , step =  13000 , current loss_val =  0.7640994080734836\n",
      "epochs =  3 , step =  14000 , current loss_val =  0.8679286337402983\n",
      "epochs =  3 , step =  15000 , current loss_val =  0.7578284709052784\n",
      "epochs =  3 , step =  16000 , current loss_val =  0.7115679183496408\n",
      "epochs =  3 , step =  17000 , current loss_val =  1.0333941000276066\n",
      "epochs =  3 , step =  18000 , current loss_val =  0.8880473297931558\n",
      "epochs =  3 , step =  19000 , current loss_val =  0.854620148244095\n",
      "epochs =  3 , step =  20000 , current loss_val =  0.9286096571236231\n",
      "epochs =  3 , step =  21000 , current loss_val =  0.8925097861072889\n",
      "epochs =  3 , step =  22000 , current loss_val =  0.883457934355546\n",
      "epochs =  3 , step =  23000 , current loss_val =  0.9406853884460227\n",
      "epochs =  3 , step =  24000 , current loss_val =  0.7687738403973269\n",
      "epochs =  3 , step =  25000 , current loss_val =  0.7600952078577076\n",
      "epochs =  3 , step =  26000 , current loss_val =  0.7707946457341358\n",
      "epochs =  3 , step =  27000 , current loss_val =  0.9313314345490638\n",
      "epochs =  3 , step =  28000 , current loss_val =  0.8299319530980046\n",
      "epochs =  3 , step =  29000 , current loss_val =  1.0792769427626638\n",
      "epochs =  3 , step =  30000 , current loss_val =  0.8251933177153618\n",
      "epochs =  3 , step =  31000 , current loss_val =  0.7655177308710559\n",
      "epochs =  3 , step =  32000 , current loss_val =  0.6904060603816758\n",
      "epochs =  3 , step =  33000 , current loss_val =  0.8554039534806276\n",
      "epochs =  3 , step =  34000 , current loss_val =  0.9299364273954911\n",
      "epochs =  3 , step =  35000 , current loss_val =  0.9015048095036371\n",
      "epochs =  4 , step =  0 , current loss_val =  0.8369303602343335\n",
      "epochs =  4 , step =  1000 , current loss_val =  0.8275052536150785\n",
      "epochs =  4 , step =  2000 , current loss_val =  0.7701659261737768\n",
      "epochs =  4 , step =  3000 , current loss_val =  0.8281551890990142\n",
      "epochs =  4 , step =  4000 , current loss_val =  0.6833356355752211\n",
      "epochs =  4 , step =  5000 , current loss_val =  1.0461903590590174\n",
      "epochs =  4 , step =  6000 , current loss_val =  0.8086598782149481\n",
      "epochs =  4 , step =  7000 , current loss_val =  0.8998176949985442\n",
      "epochs =  4 , step =  8000 , current loss_val =  0.8123826480085605\n",
      "epochs =  4 , step =  9000 , current loss_val =  0.8472309895257254\n",
      "epochs =  4 , step =  10000 , current loss_val =  0.7103718807288656\n",
      "epochs =  4 , step =  11000 , current loss_val =  0.7966932466120911\n",
      "epochs =  4 , step =  12000 , current loss_val =  0.8837219235570406\n",
      "epochs =  4 , step =  13000 , current loss_val =  0.7739970592303376\n",
      "epochs =  4 , step =  14000 , current loss_val =  0.8760286319261386\n",
      "epochs =  4 , step =  15000 , current loss_val =  0.7715719073101385\n",
      "epochs =  4 , step =  16000 , current loss_val =  0.718428348877084\n",
      "epochs =  4 , step =  17000 , current loss_val =  1.0127772127338113\n",
      "epochs =  4 , step =  18000 , current loss_val =  0.8734429165828997\n",
      "epochs =  4 , step =  19000 , current loss_val =  0.8668166917398268\n",
      "epochs =  4 , step =  20000 , current loss_val =  0.9331007124123748\n",
      "epochs =  4 , step =  21000 , current loss_val =  0.8786478572285423\n",
      "epochs =  4 , step =  22000 , current loss_val =  0.9520222133102858\n",
      "epochs =  4 , step =  23000 , current loss_val =  0.8987903035622137\n",
      "epochs =  4 , step =  24000 , current loss_val =  0.7869953957294593\n",
      "epochs =  4 , step =  25000 , current loss_val =  0.7629468480203081\n",
      "epochs =  4 , step =  26000 , current loss_val =  0.7741979381544706\n",
      "epochs =  4 , step =  27000 , current loss_val =  0.9609131374355365\n",
      "epochs =  4 , step =  28000 , current loss_val =  0.8251862075418216\n",
      "epochs =  4 , step =  29000 , current loss_val =  1.0869949820331344\n",
      "epochs =  4 , step =  30000 , current loss_val =  0.8470542342756282\n",
      "epochs =  4 , step =  31000 , current loss_val =  0.7611298564729748\n",
      "epochs =  4 , step =  32000 , current loss_val =  0.6906956010921115\n",
      "epochs =  4 , step =  33000 , current loss_val =  0.8683776858199701\n",
      "epochs =  4 , step =  34000 , current loss_val =  0.9524031175951057\n",
      "epochs =  4 , step =  35000 , current loss_val =  0.9107884467863215\n",
      "epochs =  5 , step =  0 , current loss_val =  0.8443818438143859\n",
      "epochs =  5 , step =  1000 , current loss_val =  0.8103848312027326\n",
      "epochs =  5 , step =  2000 , current loss_val =  0.7805076950286666\n",
      "epochs =  5 , step =  3000 , current loss_val =  0.8406315720405415\n",
      "epochs =  5 , step =  4000 , current loss_val =  0.6801081062523233\n",
      "epochs =  5 , step =  5000 , current loss_val =  1.0307366347679534\n",
      "epochs =  5 , step =  6000 , current loss_val =  0.8106082107440599\n",
      "epochs =  5 , step =  7000 , current loss_val =  0.9167354376788843\n",
      "epochs =  5 , step =  8000 , current loss_val =  0.8106676174866668\n",
      "epochs =  5 , step =  9000 , current loss_val =  0.8918556480542705\n",
      "epochs =  5 , step =  10000 , current loss_val =  0.7345305484204194\n",
      "epochs =  5 , step =  11000 , current loss_val =  0.8128767686405505\n",
      "epochs =  5 , step =  12000 , current loss_val =  0.8976265150072664\n",
      "epochs =  5 , step =  13000 , current loss_val =  0.7853832041836792\n",
      "epochs =  5 , step =  14000 , current loss_val =  0.8856853213215351\n",
      "epochs =  5 , step =  15000 , current loss_val =  0.7798133015847032\n",
      "epochs =  5 , step =  16000 , current loss_val =  0.7320287886490081\n",
      "epochs =  5 , step =  17000 , current loss_val =  0.9908617026506776\n",
      "epochs =  5 , step =  18000 , current loss_val =  0.8675566950839197\n",
      "epochs =  5 , step =  19000 , current loss_val =  0.8744957974671175\n",
      "epochs =  5 , step =  20000 , current loss_val =  0.9268834840850777\n",
      "epochs =  5 , step =  21000 , current loss_val =  0.8783747902173382\n",
      "epochs =  5 , step =  22000 , current loss_val =  1.0064808846456794\n",
      "epochs =  5 , step =  23000 , current loss_val =  0.8777668076687395\n",
      "epochs =  5 , step =  24000 , current loss_val =  0.8018418072419438\n",
      "epochs =  5 , step =  25000 , current loss_val =  0.7627932217701344\n",
      "epochs =  5 , step =  26000 , current loss_val =  0.7780869938490687\n",
      "epochs =  5 , step =  27000 , current loss_val =  0.9831926010656318\n",
      "epochs =  5 , step =  28000 , current loss_val =  0.8303571259965064\n",
      "epochs =  5 , step =  29000 , current loss_val =  1.0727488422954108\n",
      "epochs =  5 , step =  30000 , current loss_val =  0.8603680659975871\n",
      "epochs =  5 , step =  31000 , current loss_val =  0.7625080945627556\n",
      "epochs =  5 , step =  32000 , current loss_val =  0.7018686485926392\n",
      "epochs =  5 , step =  33000 , current loss_val =  0.8783407727500375\n",
      "epochs =  5 , step =  34000 , current loss_val =  0.9701635936563966\n",
      "epochs =  5 , step =  35000 , current loss_val =  0.9168694038715824\n",
      "epochs =  6 , step =  0 , current loss_val =  0.8480803443757627\n",
      "epochs =  6 , step =  1000 , current loss_val =  0.807089833586244\n",
      "epochs =  6 , step =  2000 , current loss_val =  0.7954035145986521\n",
      "epochs =  6 , step =  3000 , current loss_val =  0.8538633003364873\n",
      "epochs =  6 , step =  4000 , current loss_val =  0.6844393482266008\n",
      "epochs =  6 , step =  5000 , current loss_val =  0.997505566762373\n",
      "epochs =  6 , step =  6000 , current loss_val =  0.821924260911861\n",
      "epochs =  6 , step =  7000 , current loss_val =  0.9337057641762085\n",
      "epochs =  6 , step =  8000 , current loss_val =  0.8192724031922346\n",
      "epochs =  6 , step =  9000 , current loss_val =  0.9386588186581383\n",
      "epochs =  6 , step =  10000 , current loss_val =  0.7519622295218366\n",
      "epochs =  6 , step =  11000 , current loss_val =  0.8291883117168264\n",
      "epochs =  6 , step =  12000 , current loss_val =  0.8979539353126431\n",
      "epochs =  6 , step =  13000 , current loss_val =  0.7980667553402725\n",
      "epochs =  6 , step =  14000 , current loss_val =  0.8927754515226396\n",
      "epochs =  6 , step =  15000 , current loss_val =  0.7852707919316357\n",
      "epochs =  6 , step =  16000 , current loss_val =  0.7447314602963925\n",
      "epochs =  6 , step =  17000 , current loss_val =  0.9755878040099772\n",
      "epochs =  6 , step =  18000 , current loss_val =  0.8805818848635297\n",
      "epochs =  6 , step =  19000 , current loss_val =  0.8789185917327852\n",
      "epochs =  6 , step =  20000 , current loss_val =  0.9141415576075772\n",
      "epochs =  6 , step =  21000 , current loss_val =  0.8874323493854029\n",
      "epochs =  6 , step =  22000 , current loss_val =  1.044010576382818\n",
      "epochs =  6 , step =  23000 , current loss_val =  0.8694530708052433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  6 , step =  24000 , current loss_val =  0.8152598602143625\n",
      "epochs =  6 , step =  25000 , current loss_val =  0.7634181770697493\n",
      "epochs =  6 , step =  26000 , current loss_val =  0.781997636913471\n",
      "epochs =  6 , step =  27000 , current loss_val =  0.9981679245002746\n",
      "epochs =  6 , step =  28000 , current loss_val =  0.8363252767443625\n",
      "epochs =  6 , step =  29000 , current loss_val =  1.0497847178923667\n",
      "epochs =  6 , step =  30000 , current loss_val =  0.8782610038617754\n",
      "epochs =  6 , step =  31000 , current loss_val =  0.7653554536324245\n",
      "epochs =  6 , step =  32000 , current loss_val =  0.714240595243739\n",
      "epochs =  6 , step =  33000 , current loss_val =  0.8884405853870061\n",
      "epochs =  6 , step =  34000 , current loss_val =  0.9827507273087259\n",
      "epochs =  6 , step =  35000 , current loss_val =  0.9244941244924536\n",
      "epochs =  7 , step =  0 , current loss_val =  0.847982165710178\n",
      "epochs =  7 , step =  1000 , current loss_val =  0.8069465292516015\n",
      "epochs =  7 , step =  2000 , current loss_val =  0.8049179652377174\n",
      "epochs =  7 , step =  3000 , current loss_val =  0.8660096030334373\n",
      "epochs =  7 , step =  4000 , current loss_val =  0.6910628745297005\n",
      "epochs =  7 , step =  5000 , current loss_val =  0.9797676984507107\n",
      "epochs =  7 , step =  6000 , current loss_val =  0.8314968470645542\n",
      "epochs =  7 , step =  7000 , current loss_val =  0.9480094779121722\n",
      "epochs =  7 , step =  8000 , current loss_val =  0.8302835348283939\n",
      "epochs =  7 , step =  9000 , current loss_val =  0.9788042185818012\n",
      "epochs =  7 , step =  10000 , current loss_val =  0.7572826104353975\n",
      "epochs =  7 , step =  11000 , current loss_val =  0.8427611610891041\n",
      "epochs =  7 , step =  12000 , current loss_val =  0.8930769173501966\n",
      "epochs =  7 , step =  13000 , current loss_val =  0.8099706363251999\n",
      "epochs =  7 , step =  14000 , current loss_val =  0.8962039034260026\n",
      "epochs =  7 , step =  15000 , current loss_val =  0.7907033367204821\n",
      "epochs =  7 , step =  16000 , current loss_val =  0.753822168641188\n",
      "epochs =  7 , step =  17000 , current loss_val =  0.9708343726574833\n",
      "epochs =  7 , step =  18000 , current loss_val =  0.8959835113512555\n",
      "epochs =  7 , step =  19000 , current loss_val =  0.8813826148337318\n",
      "epochs =  7 , step =  20000 , current loss_val =  0.9069528058527914\n",
      "epochs =  7 , step =  21000 , current loss_val =  0.8933791718525426\n",
      "epochs =  7 , step =  22000 , current loss_val =  1.0695137246083306\n",
      "epochs =  7 , step =  23000 , current loss_val =  0.8676912567526602\n",
      "epochs =  7 , step =  24000 , current loss_val =  0.8291590143480286\n",
      "epochs =  7 , step =  25000 , current loss_val =  0.7646584434013822\n",
      "epochs =  7 , step =  26000 , current loss_val =  0.7882429132408997\n",
      "epochs =  7 , step =  27000 , current loss_val =  1.0100203351743875\n",
      "epochs =  7 , step =  28000 , current loss_val =  0.8421070206794872\n",
      "epochs =  7 , step =  29000 , current loss_val =  1.023865214690534\n",
      "epochs =  7 , step =  30000 , current loss_val =  0.8873071912454065\n",
      "epochs =  7 , step =  31000 , current loss_val =  0.7680780324357673\n",
      "epochs =  7 , step =  32000 , current loss_val =  0.7295009864716671\n",
      "epochs =  7 , step =  33000 , current loss_val =  0.9002734552610959\n",
      "epochs =  7 , step =  34000 , current loss_val =  0.9953097977343252\n",
      "epochs =  7 , step =  35000 , current loss_val =  0.9322349260349664\n",
      "epochs =  8 , step =  0 , current loss_val =  0.8466681701707557\n",
      "epochs =  8 , step =  1000 , current loss_val =  0.8109107637019809\n",
      "epochs =  8 , step =  2000 , current loss_val =  0.8070420575510344\n",
      "epochs =  8 , step =  3000 , current loss_val =  0.8761650622373349\n",
      "epochs =  8 , step =  4000 , current loss_val =  0.6973672075716865\n",
      "epochs =  8 , step =  5000 , current loss_val =  0.9731005878845687\n",
      "epochs =  8 , step =  6000 , current loss_val =  0.8368682610611169\n",
      "epochs =  8 , step =  7000 , current loss_val =  0.962625673670757\n",
      "epochs =  8 , step =  8000 , current loss_val =  0.8437028891763781\n",
      "epochs =  8 , step =  9000 , current loss_val =  1.003240261332281\n",
      "epochs =  8 , step =  10000 , current loss_val =  0.7626477966166975\n",
      "epochs =  8 , step =  11000 , current loss_val =  0.8565537396048388\n",
      "epochs =  8 , step =  12000 , current loss_val =  0.8880631964573736\n",
      "epochs =  8 , step =  13000 , current loss_val =  0.8231741534839581\n",
      "epochs =  8 , step =  14000 , current loss_val =  0.8994791523967364\n",
      "epochs =  8 , step =  15000 , current loss_val =  0.7960289606542368\n",
      "epochs =  8 , step =  16000 , current loss_val =  0.7638358176858174\n",
      "epochs =  8 , step =  17000 , current loss_val =  0.9729896160647715\n",
      "epochs =  8 , step =  18000 , current loss_val =  0.9011665667733366\n",
      "epochs =  8 , step =  19000 , current loss_val =  0.8808776912425041\n",
      "epochs =  8 , step =  20000 , current loss_val =  0.9017971473776624\n",
      "epochs =  8 , step =  21000 , current loss_val =  0.896629637446676\n",
      "epochs =  8 , step =  22000 , current loss_val =  1.0848840911755895\n",
      "epochs =  8 , step =  23000 , current loss_val =  0.8712666304793557\n",
      "epochs =  8 , step =  24000 , current loss_val =  0.8423777448199489\n",
      "epochs =  8 , step =  25000 , current loss_val =  0.767705454876823\n",
      "epochs =  8 , step =  26000 , current loss_val =  0.7978873010522523\n",
      "epochs =  8 , step =  27000 , current loss_val =  1.0212522039761929\n",
      "epochs =  8 , step =  28000 , current loss_val =  0.8493194398724941\n",
      "epochs =  8 , step =  29000 , current loss_val =  1.002482769339684\n",
      "epochs =  8 , step =  30000 , current loss_val =  0.8887132295954254\n",
      "epochs =  8 , step =  31000 , current loss_val =  0.7717806658990602\n",
      "epochs =  8 , step =  32000 , current loss_val =  0.7520922141200466\n",
      "epochs =  8 , step =  33000 , current loss_val =  0.9141495863725606\n",
      "epochs =  8 , step =  34000 , current loss_val =  1.0064772124236903\n",
      "epochs =  8 , step =  35000 , current loss_val =  0.9384539754095113\n",
      "epochs =  9 , step =  0 , current loss_val =  0.8507157711298687\n",
      "epochs =  9 , step =  1000 , current loss_val =  0.8179302277972256\n",
      "epochs =  9 , step =  2000 , current loss_val =  0.8085370572949406\n",
      "epochs =  9 , step =  3000 , current loss_val =  0.8852427201872656\n",
      "epochs =  9 , step =  4000 , current loss_val =  0.70523058498448\n",
      "epochs =  9 , step =  5000 , current loss_val =  0.9683090423607416\n",
      "epochs =  9 , step =  6000 , current loss_val =  0.8406500787494917\n",
      "epochs =  9 , step =  7000 , current loss_val =  0.9768661889182028\n",
      "epochs =  9 , step =  8000 , current loss_val =  0.859390231107395\n",
      "epochs =  9 , step =  9000 , current loss_val =  1.0111026153671525\n",
      "epochs =  9 , step =  10000 , current loss_val =  0.7722426656022782\n",
      "epochs =  9 , step =  11000 , current loss_val =  0.8693518269406989\n",
      "epochs =  9 , step =  12000 , current loss_val =  0.8957671108944281\n",
      "epochs =  9 , step =  13000 , current loss_val =  0.8348000635791467\n",
      "epochs =  9 , step =  14000 , current loss_val =  0.9069937528724579\n",
      "epochs =  9 , step =  15000 , current loss_val =  0.803187014445887\n",
      "epochs =  9 , step =  16000 , current loss_val =  0.778451523609801\n",
      "epochs =  9 , step =  17000 , current loss_val =  0.9821229653008443\n",
      "epochs =  9 , step =  18000 , current loss_val =  0.904586461376479\n",
      "epochs =  9 , step =  19000 , current loss_val =  0.8810985273175459\n",
      "epochs =  9 , step =  20000 , current loss_val =  0.8992053283641825\n",
      "epochs =  9 , step =  21000 , current loss_val =  0.8999802834945845\n",
      "epochs =  9 , step =  22000 , current loss_val =  1.0948695551109828\n",
      "epochs =  9 , step =  23000 , current loss_val =  0.8768051347474686\n",
      "epochs =  9 , step =  24000 , current loss_val =  0.8606028807531172\n",
      "epochs =  9 , step =  25000 , current loss_val =  0.7733349133710998\n",
      "epochs =  9 , step =  26000 , current loss_val =  0.8070757214215913\n",
      "epochs =  9 , step =  27000 , current loss_val =  1.0293796897153704\n",
      "epochs =  9 , step =  28000 , current loss_val =  0.8593558599738459\n",
      "epochs =  9 , step =  29000 , current loss_val =  0.9930002604508508\n",
      "epochs =  9 , step =  30000 , current loss_val =  0.8907032744572337\n",
      "epochs =  9 , step =  31000 , current loss_val =  0.7758303743494027\n",
      "epochs =  9 , step =  32000 , current loss_val =  0.7769232896903264\n",
      "epochs =  9 , step =  33000 , current loss_val =  0.9277677917726973\n",
      "epochs =  9 , step =  34000 , current loss_val =  1.0167315649912319\n",
      "epochs =  9 , step =  35000 , current loss_val =  0.9427709171121379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  10 , step =  0 , current loss_val =  0.8604078504461523\n",
      "epochs =  10 , step =  1000 , current loss_val =  0.825959454593039\n",
      "epochs =  10 , step =  2000 , current loss_val =  0.8128480276370887\n",
      "epochs =  10 , step =  3000 , current loss_val =  0.8990415784316877\n",
      "epochs =  10 , step =  4000 , current loss_val =  0.7147234242348115\n",
      "epochs =  10 , step =  5000 , current loss_val =  0.9819235336390575\n",
      "epochs =  10 , step =  6000 , current loss_val =  0.8459835567335074\n",
      "epochs =  10 , step =  7000 , current loss_val =  0.9906220511946217\n",
      "epochs =  10 , step =  8000 , current loss_val =  0.8783342107989793\n",
      "epochs =  10 , step =  9000 , current loss_val =  1.0154426711770377\n",
      "epochs =  10 , step =  10000 , current loss_val =  0.7845103076099829\n",
      "epochs =  10 , step =  11000 , current loss_val =  0.8858153057145791\n",
      "epochs =  10 , step =  12000 , current loss_val =  0.9000013127650599\n",
      "epochs =  10 , step =  13000 , current loss_val =  0.8465436511293634\n",
      "epochs =  10 , step =  14000 , current loss_val =  0.9175224412186485\n",
      "epochs =  10 , step =  15000 , current loss_val =  0.8095265087446659\n",
      "epochs =  10 , step =  16000 , current loss_val =  0.795571995793253\n",
      "epochs =  10 , step =  17000 , current loss_val =  0.9984981011960303\n",
      "epochs =  10 , step =  18000 , current loss_val =  0.9042290317332436\n",
      "epochs =  10 , step =  19000 , current loss_val =  0.887705470819198\n",
      "epochs =  10 , step =  20000 , current loss_val =  0.898576302969926\n",
      "epochs =  10 , step =  21000 , current loss_val =  0.9037458595411627\n",
      "epochs =  10 , step =  22000 , current loss_val =  1.1011457332734829\n",
      "epochs =  10 , step =  23000 , current loss_val =  0.8834760437927138\n",
      "epochs =  10 , step =  24000 , current loss_val =  0.8809470512978117\n",
      "epochs =  10 , step =  25000 , current loss_val =  0.779878885103569\n",
      "epochs =  10 , step =  26000 , current loss_val =  0.8152080394029733\n",
      "epochs =  10 , step =  27000 , current loss_val =  1.036607876607203\n",
      "epochs =  10 , step =  28000 , current loss_val =  0.8701175449096789\n",
      "epochs =  10 , step =  29000 , current loss_val =  0.9846337490171774\n",
      "epochs =  10 , step =  30000 , current loss_val =  0.8934747359365119\n",
      "epochs =  10 , step =  31000 , current loss_val =  0.7792468251368752\n",
      "epochs =  10 , step =  32000 , current loss_val =  0.7999006514689572\n",
      "epochs =  10 , step =  33000 , current loss_val =  0.9432691237239285\n",
      "epochs =  10 , step =  34000 , current loss_val =  1.0314084623167359\n",
      "epochs =  10 , step =  35000 , current loss_val =  0.9492170914912195\n",
      "epochs =  11 , step =  0 , current loss_val =  0.8713176850551938\n",
      "epochs =  11 , step =  1000 , current loss_val =  0.8316803416120926\n",
      "epochs =  11 , step =  2000 , current loss_val =  0.8194909199164477\n",
      "epochs =  11 , step =  3000 , current loss_val =  0.9142820820125724\n",
      "epochs =  11 , step =  4000 , current loss_val =  0.7237746810829171\n",
      "epochs =  11 , step =  5000 , current loss_val =  0.9944949940704602\n",
      "epochs =  11 , step =  6000 , current loss_val =  0.8492498960916934\n",
      "epochs =  11 , step =  7000 , current loss_val =  1.0049514353658975\n",
      "epochs =  11 , step =  8000 , current loss_val =  0.8937682260038822\n",
      "epochs =  11 , step =  9000 , current loss_val =  1.0180980621703268\n",
      "epochs =  11 , step =  10000 , current loss_val =  0.799138048909966\n",
      "epochs =  11 , step =  11000 , current loss_val =  0.9044942233161063\n",
      "epochs =  11 , step =  12000 , current loss_val =  0.9042096957580336\n",
      "epochs =  11 , step =  13000 , current loss_val =  0.8589799579190022\n",
      "epochs =  11 , step =  14000 , current loss_val =  0.9305323758502098\n",
      "epochs =  11 , step =  15000 , current loss_val =  0.8155959688607662\n",
      "epochs =  11 , step =  16000 , current loss_val =  0.8142756633588951\n",
      "epochs =  11 , step =  17000 , current loss_val =  1.0155740216820324\n",
      "epochs =  11 , step =  18000 , current loss_val =  0.8992571026002394\n",
      "epochs =  11 , step =  19000 , current loss_val =  0.8989494325731223\n",
      "epochs =  11 , step =  20000 , current loss_val =  0.8975629068044516\n",
      "epochs =  11 , step =  21000 , current loss_val =  0.911943671547387\n",
      "epochs =  11 , step =  22000 , current loss_val =  1.104203629988133\n",
      "epochs =  11 , step =  23000 , current loss_val =  0.8922855258402576\n",
      "epochs =  11 , step =  24000 , current loss_val =  0.8998486404632071\n",
      "epochs =  11 , step =  25000 , current loss_val =  0.7866213729388292\n",
      "epochs =  11 , step =  26000 , current loss_val =  0.8254811454424658\n",
      "epochs =  11 , step =  27000 , current loss_val =  1.0442449319957947\n",
      "epochs =  11 , step =  28000 , current loss_val =  0.8810871147195348\n",
      "epochs =  11 , step =  29000 , current loss_val =  0.9728553586009425\n",
      "epochs =  11 , step =  30000 , current loss_val =  0.8950097711517644\n",
      "epochs =  11 , step =  31000 , current loss_val =  0.7818385141559984\n",
      "epochs =  11 , step =  32000 , current loss_val =  0.8207114407296446\n",
      "epochs =  11 , step =  33000 , current loss_val =  0.9575683499152208\n",
      "epochs =  11 , step =  34000 , current loss_val =  1.0473982238953587\n",
      "epochs =  11 , step =  35000 , current loss_val =  0.9606656296590955\n",
      "epochs =  12 , step =  0 , current loss_val =  0.8841591413148815\n",
      "epochs =  12 , step =  1000 , current loss_val =  0.837164740356644\n",
      "epochs =  12 , step =  2000 , current loss_val =  0.8270917664445949\n",
      "epochs =  12 , step =  3000 , current loss_val =  0.9302543524499219\n",
      "epochs =  12 , step =  4000 , current loss_val =  0.7319143226573035\n",
      "epochs =  12 , step =  5000 , current loss_val =  0.9905842072405387\n",
      "epochs =  12 , step =  6000 , current loss_val =  0.8488619334202372\n",
      "epochs =  12 , step =  7000 , current loss_val =  1.0176954125800772\n",
      "epochs =  12 , step =  8000 , current loss_val =  0.9044038603926008\n",
      "epochs =  12 , step =  9000 , current loss_val =  1.0205322593465809\n",
      "epochs =  12 , step =  10000 , current loss_val =  0.8154920429533381\n",
      "epochs =  12 , step =  11000 , current loss_val =  0.9211499551296978\n",
      "epochs =  12 , step =  12000 , current loss_val =  0.908654039040353\n",
      "epochs =  12 , step =  13000 , current loss_val =  0.8724939481898597\n",
      "epochs =  12 , step =  14000 , current loss_val =  0.9440068149424258\n",
      "epochs =  12 , step =  15000 , current loss_val =  0.8223866232040695\n",
      "epochs =  12 , step =  16000 , current loss_val =  0.8336104246186397\n",
      "epochs =  12 , step =  17000 , current loss_val =  1.0265250147719516\n",
      "epochs =  12 , step =  18000 , current loss_val =  0.8898779171799863\n",
      "epochs =  12 , step =  19000 , current loss_val =  0.9101403595856136\n",
      "epochs =  12 , step =  20000 , current loss_val =  0.8953116264586856\n",
      "epochs =  12 , step =  21000 , current loss_val =  0.9242094914083552\n",
      "epochs =  12 , step =  22000 , current loss_val =  1.1059448453080858\n",
      "epochs =  12 , step =  23000 , current loss_val =  0.9024075400245504\n",
      "epochs =  12 , step =  24000 , current loss_val =  0.9140382781536004\n",
      "epochs =  12 , step =  25000 , current loss_val =  0.7928645641720443\n",
      "epochs =  12 , step =  26000 , current loss_val =  0.8353278376228854\n",
      "epochs =  12 , step =  27000 , current loss_val =  1.055089456912118\n",
      "epochs =  12 , step =  28000 , current loss_val =  0.8918415015109479\n",
      "epochs =  12 , step =  29000 , current loss_val =  0.9619373700099133\n",
      "epochs =  12 , step =  30000 , current loss_val =  0.8993037289633814\n",
      "epochs =  12 , step =  31000 , current loss_val =  0.7856018395667851\n",
      "epochs =  12 , step =  32000 , current loss_val =  0.8395641362660071\n",
      "epochs =  12 , step =  33000 , current loss_val =  0.9701070781120814\n",
      "epochs =  12 , step =  34000 , current loss_val =  1.060964125902015\n",
      "epochs =  12 , step =  35000 , current loss_val =  0.9740011163126362\n",
      "epochs =  13 , step =  0 , current loss_val =  0.8978936974878438\n",
      "epochs =  13 , step =  1000 , current loss_val =  0.8459349670317513\n",
      "epochs =  13 , step =  2000 , current loss_val =  0.8365627294965149\n",
      "epochs =  13 , step =  3000 , current loss_val =  0.9451681548317028\n",
      "epochs =  13 , step =  4000 , current loss_val =  0.7400070304378679\n",
      "epochs =  13 , step =  5000 , current loss_val =  0.9894038610754143\n",
      "epochs =  13 , step =  6000 , current loss_val =  0.8471212333831555\n",
      "epochs =  13 , step =  7000 , current loss_val =  1.0276710639551452\n",
      "epochs =  13 , step =  8000 , current loss_val =  0.9133565317272537\n",
      "epochs =  13 , step =  9000 , current loss_val =  1.0254654199281286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  13 , step =  10000 , current loss_val =  0.8331665885320529\n",
      "epochs =  13 , step =  11000 , current loss_val =  0.9338648972548412\n",
      "epochs =  13 , step =  12000 , current loss_val =  0.9160153186087786\n",
      "epochs =  13 , step =  13000 , current loss_val =  0.8863897918707777\n",
      "epochs =  13 , step =  14000 , current loss_val =  0.9587988862189436\n",
      "epochs =  13 , step =  15000 , current loss_val =  0.8306122732302963\n",
      "epochs =  13 , step =  16000 , current loss_val =  0.8520035096320041\n",
      "epochs =  13 , step =  17000 , current loss_val =  1.029139250407275\n",
      "epochs =  13 , step =  18000 , current loss_val =  0.8842878764287816\n",
      "epochs =  13 , step =  19000 , current loss_val =  0.9252169818211534\n",
      "epochs =  13 , step =  20000 , current loss_val =  0.8939555394095797\n",
      "epochs =  13 , step =  21000 , current loss_val =  0.9364532492175319\n",
      "epochs =  13 , step =  22000 , current loss_val =  1.1061133572256354\n",
      "epochs =  13 , step =  23000 , current loss_val =  0.9127927093027846\n",
      "epochs =  13 , step =  24000 , current loss_val =  0.9244256402712955\n",
      "epochs =  13 , step =  25000 , current loss_val =  0.7977650192425313\n",
      "epochs =  13 , step =  26000 , current loss_val =  0.8436448353347443\n",
      "epochs =  13 , step =  27000 , current loss_val =  1.0656727360399507\n",
      "epochs =  13 , step =  28000 , current loss_val =  0.9020615345599517\n",
      "epochs =  13 , step =  29000 , current loss_val =  0.9532814733913438\n",
      "epochs =  13 , step =  30000 , current loss_val =  0.9105511184865884\n",
      "epochs =  13 , step =  31000 , current loss_val =  0.7925411267800008\n",
      "epochs =  13 , step =  32000 , current loss_val =  0.8573259585368317\n",
      "epochs =  13 , step =  33000 , current loss_val =  0.9813759116646876\n",
      "epochs =  13 , step =  34000 , current loss_val =  1.0702629372202714\n",
      "epochs =  13 , step =  35000 , current loss_val =  0.9859896866827476\n",
      "epochs =  14 , step =  0 , current loss_val =  0.9117097942087381\n",
      "epochs =  14 , step =  1000 , current loss_val =  0.8579364431128426\n",
      "epochs =  14 , step =  2000 , current loss_val =  0.8481002661747158\n",
      "epochs =  14 , step =  3000 , current loss_val =  0.9585675485852415\n",
      "epochs =  14 , step =  4000 , current loss_val =  0.749468383260485\n",
      "epochs =  14 , step =  5000 , current loss_val =  0.991546846883579\n",
      "epochs =  14 , step =  6000 , current loss_val =  0.8459958209060044\n",
      "epochs =  14 , step =  7000 , current loss_val =  1.035917522433683\n",
      "epochs =  14 , step =  8000 , current loss_val =  0.9203520721042575\n",
      "epochs =  14 , step =  9000 , current loss_val =  1.0309327615860342\n",
      "epochs =  14 , step =  10000 , current loss_val =  0.8511826770236168\n",
      "epochs =  14 , step =  11000 , current loss_val =  0.9431047208024381\n",
      "epochs =  14 , step =  12000 , current loss_val =  0.9274683364666261\n",
      "epochs =  14 , step =  13000 , current loss_val =  0.8999246679638986\n",
      "epochs =  14 , step =  14000 , current loss_val =  0.9756413364159011\n",
      "epochs =  14 , step =  15000 , current loss_val =  0.8393121259546863\n",
      "epochs =  14 , step =  16000 , current loss_val =  0.8685209659517567\n",
      "epochs =  14 , step =  17000 , current loss_val =  1.0253363884681943\n",
      "epochs =  14 , step =  18000 , current loss_val =  0.8805063066590556\n",
      "epochs =  14 , step =  19000 , current loss_val =  0.9383919651341509\n",
      "epochs =  14 , step =  20000 , current loss_val =  0.8932934766350152\n",
      "epochs =  14 , step =  21000 , current loss_val =  0.9496493863812554\n",
      "epochs =  14 , step =  22000 , current loss_val =  1.1060113327494216\n",
      "epochs =  14 , step =  23000 , current loss_val =  0.9231735153769838\n",
      "epochs =  14 , step =  24000 , current loss_val =  0.9330751740319669\n",
      "epochs =  14 , step =  25000 , current loss_val =  0.8030820244267813\n",
      "epochs =  14 , step =  26000 , current loss_val =  0.8500200491902741\n",
      "epochs =  14 , step =  27000 , current loss_val =  1.074187772838317\n",
      "epochs =  14 , step =  28000 , current loss_val =  0.9106103214682482\n",
      "epochs =  14 , step =  29000 , current loss_val =  0.9422713036917989\n",
      "epochs =  14 , step =  30000 , current loss_val =  0.9228258845870787\n",
      "epochs =  14 , step =  31000 , current loss_val =  0.8017776511273622\n",
      "epochs =  14 , step =  32000 , current loss_val =  0.8730612313319239\n",
      "epochs =  14 , step =  33000 , current loss_val =  0.9904110047785826\n",
      "epochs =  14 , step =  34000 , current loss_val =  1.0784030781076128\n",
      "epochs =  14 , step =  35000 , current loss_val =  0.9975782967765766\n",
      "epochs =  15 , step =  0 , current loss_val =  0.9256102510527568\n",
      "epochs =  15 , step =  1000 , current loss_val =  0.8710566741095038\n",
      "epochs =  15 , step =  2000 , current loss_val =  0.8603834606687762\n",
      "epochs =  15 , step =  3000 , current loss_val =  0.9719712371761184\n",
      "epochs =  15 , step =  4000 , current loss_val =  0.7596758747032735\n",
      "epochs =  15 , step =  5000 , current loss_val =  0.9921441614625816\n",
      "epochs =  15 , step =  6000 , current loss_val =  0.8462054284648691\n",
      "epochs =  15 , step =  7000 , current loss_val =  1.0435841420552183\n",
      "epochs =  15 , step =  8000 , current loss_val =  0.9260772930705437\n",
      "epochs =  15 , step =  9000 , current loss_val =  1.0336820077592965\n",
      "epochs =  15 , step =  10000 , current loss_val =  0.8683472639767679\n",
      "epochs =  15 , step =  11000 , current loss_val =  0.9503791076522708\n",
      "epochs =  15 , step =  12000 , current loss_val =  0.9414511782782354\n",
      "epochs =  15 , step =  13000 , current loss_val =  0.9137718223346986\n",
      "epochs =  15 , step =  14000 , current loss_val =  0.9914629524550143\n",
      "epochs =  15 , step =  15000 , current loss_val =  0.8482552228981699\n",
      "epochs =  15 , step =  16000 , current loss_val =  0.8840304938208625\n",
      "epochs =  15 , step =  17000 , current loss_val =  1.016757628049919\n",
      "epochs =  15 , step =  18000 , current loss_val =  0.8743806568195025\n",
      "epochs =  15 , step =  19000 , current loss_val =  0.9501325959629139\n",
      "epochs =  15 , step =  20000 , current loss_val =  0.8920527645768406\n",
      "epochs =  15 , step =  21000 , current loss_val =  0.9614630742540602\n",
      "epochs =  15 , step =  22000 , current loss_val =  1.1058499898032053\n",
      "epochs =  15 , step =  23000 , current loss_val =  0.9339333893292604\n",
      "epochs =  15 , step =  24000 , current loss_val =  0.9404512240035479\n",
      "epochs =  15 , step =  25000 , current loss_val =  0.8099516923890607\n",
      "epochs =  15 , step =  26000 , current loss_val =  0.8558624201149643\n",
      "epochs =  15 , step =  27000 , current loss_val =  1.0830034545672322\n",
      "epochs =  15 , step =  28000 , current loss_val =  0.9181951975870443\n",
      "epochs =  15 , step =  29000 , current loss_val =  0.9317711496800295\n",
      "epochs =  15 , step =  30000 , current loss_val =  0.9364585336834745\n",
      "epochs =  15 , step =  31000 , current loss_val =  0.8095493443615327\n",
      "epochs =  15 , step =  32000 , current loss_val =  0.8870971707087596\n",
      "epochs =  15 , step =  33000 , current loss_val =  0.9990475557832802\n",
      "epochs =  15 , step =  34000 , current loss_val =  1.0896746584817207\n",
      "epochs =  15 , step =  35000 , current loss_val =  1.0100588107565842\n",
      "epochs =  16 , step =  0 , current loss_val =  0.9403392911816182\n",
      "epochs =  16 , step =  1000 , current loss_val =  0.8844233336830203\n",
      "epochs =  16 , step =  2000 , current loss_val =  0.8721527268947632\n",
      "epochs =  16 , step =  3000 , current loss_val =  0.986458126412815\n",
      "epochs =  16 , step =  4000 , current loss_val =  0.7689513048729822\n",
      "epochs =  16 , step =  5000 , current loss_val =  0.9932592846077575\n",
      "epochs =  16 , step =  6000 , current loss_val =  0.8482844550443008\n",
      "epochs =  16 , step =  7000 , current loss_val =  1.0508588431989285\n",
      "epochs =  16 , step =  8000 , current loss_val =  0.9327157426476589\n",
      "epochs =  16 , step =  9000 , current loss_val =  1.0350684448218677\n",
      "epochs =  16 , step =  10000 , current loss_val =  0.8846177431731834\n",
      "epochs =  16 , step =  11000 , current loss_val =  0.9584769518022477\n",
      "epochs =  16 , step =  12000 , current loss_val =  0.9563895928781805\n",
      "epochs =  16 , step =  13000 , current loss_val =  0.9286844050430143\n",
      "epochs =  16 , step =  14000 , current loss_val =  1.0049914118849825\n",
      "epochs =  16 , step =  15000 , current loss_val =  0.8575874263399037\n",
      "epochs =  16 , step =  16000 , current loss_val =  0.898099068970206\n",
      "epochs =  16 , step =  17000 , current loss_val =  1.0100169950044153\n",
      "epochs =  16 , step =  18000 , current loss_val =  0.8730162025030946\n",
      "epochs =  16 , step =  19000 , current loss_val =  0.96063572612862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  16 , step =  20000 , current loss_val =  0.8916580496590656\n",
      "epochs =  16 , step =  21000 , current loss_val =  0.9720917522039862\n",
      "epochs =  16 , step =  22000 , current loss_val =  1.1037955334618292\n",
      "epochs =  16 , step =  23000 , current loss_val =  0.9441207796057902\n",
      "epochs =  16 , step =  24000 , current loss_val =  0.9493239148996776\n",
      "epochs =  16 , step =  25000 , current loss_val =  0.8174370216837225\n",
      "epochs =  16 , step =  26000 , current loss_val =  0.8618062816330354\n",
      "epochs =  16 , step =  27000 , current loss_val =  1.0946506151639621\n",
      "epochs =  16 , step =  28000 , current loss_val =  0.9248980641259265\n",
      "epochs =  16 , step =  29000 , current loss_val =  0.9228319850024087\n",
      "epochs =  16 , step =  30000 , current loss_val =  0.9496101194460687\n",
      "epochs =  16 , step =  31000 , current loss_val =  0.8172840716926102\n",
      "epochs =  16 , step =  32000 , current loss_val =  0.900607937035025\n",
      "epochs =  16 , step =  33000 , current loss_val =  1.0088431907926192\n",
      "epochs =  16 , step =  34000 , current loss_val =  1.1009770514939614\n",
      "epochs =  16 , step =  35000 , current loss_val =  1.022185662801295\n",
      "epochs =  17 , step =  0 , current loss_val =  0.954564468868941\n",
      "epochs =  17 , step =  1000 , current loss_val =  0.8968746088297771\n",
      "epochs =  17 , step =  2000 , current loss_val =  0.8843051551874428\n",
      "epochs =  17 , step =  3000 , current loss_val =  1.000971764131212\n",
      "epochs =  17 , step =  4000 , current loss_val =  0.7777519159166975\n",
      "epochs =  17 , step =  5000 , current loss_val =  0.9966550187356583\n",
      "epochs =  17 , step =  6000 , current loss_val =  0.8488795209760841\n",
      "epochs =  17 , step =  7000 , current loss_val =  1.0561696511598284\n",
      "epochs =  17 , step =  8000 , current loss_val =  0.9398830335007504\n",
      "epochs =  17 , step =  9000 , current loss_val =  1.0402439411429267\n",
      "epochs =  17 , step =  10000 , current loss_val =  0.9000578864882747\n",
      "epochs =  17 , step =  11000 , current loss_val =  0.9676050847676546\n",
      "epochs =  17 , step =  12000 , current loss_val =  0.9697307398379468\n",
      "epochs =  17 , step =  13000 , current loss_val =  0.9447053485495729\n",
      "epochs =  17 , step =  14000 , current loss_val =  1.0162770331834954\n",
      "epochs =  17 , step =  15000 , current loss_val =  0.8662571168962303\n",
      "epochs =  17 , step =  16000 , current loss_val =  0.9101864311744803\n",
      "epochs =  17 , step =  17000 , current loss_val =  1.0101215922778395\n",
      "epochs =  17 , step =  18000 , current loss_val =  0.8791121692419562\n",
      "epochs =  17 , step =  19000 , current loss_val =  0.9709872176453812\n",
      "epochs =  17 , step =  20000 , current loss_val =  0.8910413207514695\n",
      "epochs =  17 , step =  21000 , current loss_val =  0.9809891230794133\n",
      "epochs =  17 , step =  22000 , current loss_val =  1.1002890659229698\n",
      "epochs =  17 , step =  23000 , current loss_val =  0.9535761651641869\n",
      "epochs =  17 , step =  24000 , current loss_val =  0.9603498457748301\n",
      "epochs =  17 , step =  25000 , current loss_val =  0.8254750538881804\n",
      "epochs =  17 , step =  26000 , current loss_val =  0.8676289518966204\n",
      "epochs =  17 , step =  27000 , current loss_val =  1.1090763592597372\n",
      "epochs =  17 , step =  28000 , current loss_val =  0.9310986224103235\n",
      "epochs =  17 , step =  29000 , current loss_val =  0.9169070013386534\n",
      "epochs =  17 , step =  30000 , current loss_val =  0.9601637846770648\n",
      "epochs =  17 , step =  31000 , current loss_val =  0.8262282579737246\n",
      "epochs =  17 , step =  32000 , current loss_val =  0.9135441350631849\n",
      "epochs =  17 , step =  33000 , current loss_val =  1.0188558721239618\n",
      "epochs =  17 , step =  34000 , current loss_val =  1.1094783510970199\n",
      "epochs =  17 , step =  35000 , current loss_val =  1.0346573725096047\n",
      "epochs =  18 , step =  0 , current loss_val =  0.9661278266022019\n",
      "epochs =  18 , step =  1000 , current loss_val =  0.9083736375071605\n",
      "epochs =  18 , step =  2000 , current loss_val =  0.8969946979159349\n",
      "epochs =  18 , step =  3000 , current loss_val =  1.0143430276066654\n",
      "epochs =  18 , step =  4000 , current loss_val =  0.7864612158253764\n",
      "epochs =  18 , step =  5000 , current loss_val =  1.0012648003698996\n",
      "epochs =  18 , step =  6000 , current loss_val =  0.847906258636726\n",
      "epochs =  18 , step =  7000 , current loss_val =  1.0613072746176566\n",
      "epochs =  18 , step =  8000 , current loss_val =  0.9470848613576228\n",
      "epochs =  18 , step =  9000 , current loss_val =  1.0495290542469458\n",
      "epochs =  18 , step =  10000 , current loss_val =  0.9139670384358036\n",
      "epochs =  18 , step =  11000 , current loss_val =  0.976734788535299\n",
      "epochs =  18 , step =  12000 , current loss_val =  0.9817024647310788\n",
      "epochs =  18 , step =  13000 , current loss_val =  0.9602999280432043\n",
      "epochs =  18 , step =  14000 , current loss_val =  1.025224513151211\n",
      "epochs =  18 , step =  15000 , current loss_val =  0.8745139411564741\n",
      "epochs =  18 , step =  16000 , current loss_val =  0.9211271417564239\n",
      "epochs =  18 , step =  17000 , current loss_val =  1.0145488788117887\n",
      "epochs =  18 , step =  18000 , current loss_val =  0.891016724714349\n",
      "epochs =  18 , step =  19000 , current loss_val =  0.9821928461422883\n",
      "epochs =  18 , step =  20000 , current loss_val =  0.888862270077883\n",
      "epochs =  18 , step =  21000 , current loss_val =  0.9871293887050712\n",
      "epochs =  18 , step =  22000 , current loss_val =  1.0946951146751227\n",
      "epochs =  18 , step =  23000 , current loss_val =  0.9619638779616623\n",
      "epochs =  18 , step =  24000 , current loss_val =  0.9722279990125186\n",
      "epochs =  18 , step =  25000 , current loss_val =  0.833423997594027\n",
      "epochs =  18 , step =  26000 , current loss_val =  0.8741875800565312\n",
      "epochs =  18 , step =  27000 , current loss_val =  1.1243651344741767\n",
      "epochs =  18 , step =  28000 , current loss_val =  0.9371279874468456\n",
      "epochs =  18 , step =  29000 , current loss_val =  0.9146094052713406\n",
      "epochs =  18 , step =  30000 , current loss_val =  0.9651318428046716\n",
      "epochs =  18 , step =  31000 , current loss_val =  0.8355867569054057\n",
      "epochs =  18 , step =  32000 , current loss_val =  0.925634582341138\n",
      "epochs =  18 , step =  33000 , current loss_val =  1.0270798649110782\n",
      "epochs =  18 , step =  34000 , current loss_val =  1.1144971796452212\n",
      "epochs =  18 , step =  35000 , current loss_val =  1.0463023593190237\n",
      "epochs =  19 , step =  0 , current loss_val =  0.9748659125281788\n",
      "epochs =  19 , step =  1000 , current loss_val =  0.9190589991078058\n",
      "epochs =  19 , step =  2000 , current loss_val =  0.9098363965736022\n",
      "epochs =  19 , step =  3000 , current loss_val =  1.025925195214454\n",
      "epochs =  19 , step =  4000 , current loss_val =  0.7948206361894733\n",
      "epochs =  19 , step =  5000 , current loss_val =  1.0063585690568113\n",
      "epochs =  19 , step =  6000 , current loss_val =  0.8492380184594109\n",
      "epochs =  19 , step =  7000 , current loss_val =  1.0671291624269699\n",
      "epochs =  19 , step =  8000 , current loss_val =  0.9542131512813337\n",
      "epochs =  19 , step =  9000 , current loss_val =  1.0578275754676056\n",
      "epochs =  19 , step =  10000 , current loss_val =  0.9256210278896064\n",
      "epochs =  19 , step =  11000 , current loss_val =  0.9861893600642648\n",
      "epochs =  19 , step =  12000 , current loss_val =  0.9945603046950751\n",
      "epochs =  19 , step =  13000 , current loss_val =  0.9754930572460374\n",
      "epochs =  19 , step =  14000 , current loss_val =  1.0320763044164714\n",
      "epochs =  19 , step =  15000 , current loss_val =  0.8819880009427188\n",
      "epochs =  19 , step =  16000 , current loss_val =  0.9295212759639009\n",
      "epochs =  19 , step =  17000 , current loss_val =  1.020432071709141\n",
      "epochs =  19 , step =  18000 , current loss_val =  0.9063131187059044\n",
      "epochs =  19 , step =  19000 , current loss_val =  0.992710949074494\n",
      "epochs =  19 , step =  20000 , current loss_val =  0.8854522984457989\n",
      "epochs =  19 , step =  21000 , current loss_val =  0.9916390351723746\n",
      "epochs =  19 , step =  22000 , current loss_val =  1.0853378097656667\n",
      "epochs =  19 , step =  23000 , current loss_val =  0.9684910803974425\n",
      "epochs =  19 , step =  24000 , current loss_val =  0.9817501203764071\n",
      "epochs =  19 , step =  25000 , current loss_val =  0.840904313538963\n",
      "epochs =  19 , step =  26000 , current loss_val =  0.8822291550081204\n",
      "epochs =  19 , step =  27000 , current loss_val =  1.1382408197098812\n",
      "epochs =  19 , step =  28000 , current loss_val =  0.9434888043373546\n",
      "epochs =  19 , step =  29000 , current loss_val =  0.9137336331463743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  19 , step =  30000 , current loss_val =  0.9639330154454562\n",
      "epochs =  19 , step =  31000 , current loss_val =  0.8443820361819248\n",
      "epochs =  19 , step =  32000 , current loss_val =  0.9371585498931524\n",
      "epochs =  19 , step =  33000 , current loss_val =  1.034254044344669\n",
      "epochs =  19 , step =  34000 , current loss_val =  1.1172758881920521\n",
      "epochs =  19 , step =  35000 , current loss_val =  1.0561273195753376\n",
      "\n",
      "elapsed time =  0:06:25.998816\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 100     # hidden 1 nodes\n",
    "o_nodes = 10       # output nodes\n",
    "lr = 0.1           # learning rate\n",
    "epochs = 20         # epochs\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "accuracy_val_list = []    # training data accuracy val\n",
    "validation_accuracy_val_list = []    # validation data loss val\n",
    "\n",
    "\n",
    "nn = NeuralNetwork(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for step in range(len(training_data)):  # train\n",
    "    \n",
    "        # input_data, target_data normalize        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[step, 0])] = 0.99\n",
    "    \n",
    "        input_data = ((training_data[step, 1:] / 255.0) * 0.99) + 0.01\n",
    "    \n",
    "        nn.train( np.array(input_data, ndmin=2), np.array(target_data, ndmin=2) )  # train 할 경우에 행렬로 입력\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\"epochs = \", i, \", step = \", step,  \", current loss_val = \", nn.loss_val())\n",
    "        \n",
    "        cur_loss_val = nn.loss_val()\n",
    "    \n",
    "        loss_val_list.append(cur_loss_val)\n",
    "    \n",
    "    training_accuracy = nn.accuracy(training_data[:, 1:], training_data[:, 0])[0]\n",
    "    \n",
    "    validation_accuracy = nn.accuracy(test_data[:, 1:], test_data[:, 0])[0]\n",
    "    \n",
    "    accuracy_val_list.append(training_accuracy)\n",
    "    \n",
    "    validation_accuracy_val_list.append(validation_accuracy)\n",
    "\n",
    "end_time = datetime.now() \n",
    "\n",
    "print(\"\\nelapsed time = \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (24000, 785)\n",
      "test_data[0,0] =  9.0 , len(test_data[0]) =  785\n",
      "Accuracy =  97.033  %\n"
     ]
    }
   ],
   "source": [
    "# 0~9 숫자 이미지가 784개의 숫자 (28X28) 로 구성되어 있는 test data 읽어옴\n",
    "\n",
    "try:\n",
    "    test_input_data = test_data[ : , 1: ]\n",
    "    test_target_data = test_data[ : , 0 ]\n",
    "\n",
    "    print(\"test_data.shape = \", test_data.shape)\n",
    "    print(\"test_data[0,0] = \", test_data[0,0], \", len(test_data[0]) = \", len(test_data[0]))\n",
    "\n",
    "    # measure accuracy\n",
    "    (accuracy_ret, false_list) = nn.accuracy(test_input_data, test_target_data)   \n",
    "\n",
    "    print('Accuracy = ', np.round(100*accuracy_ret, 3), ' %')\n",
    "    \n",
    "except Exception as err:\n",
    "    \n",
    "    print('Exception occur !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 과적합 확인\n",
    "\n",
    "plt.title('Training / Validation Accuracy Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.plot(accuracy_val_list, label='training acc')\n",
    "plt.plot(validation_accuracy_val_list, label='validation acc')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgcVbn48e9LEiCQhbBkiGwBiZEAASQCGqIjILIpKHgRuSwBjMrld1G4rMoNIioKAldlC4sE2RGQLQQIpBNQE0kwK0kgOwkJgewzYUgmeX9/nGqmp6eX6uquruqu9/M883RXdZ06p85Uv33qVNUpUVWMMcYkx1ZRF8AYY0x1WeA3xpiEscBvjDEJY4HfGGMSxgK/McYkjAV+Y4xJGAv8xkRIRBpFZEnU5ag0EblARFJRl8PkZoHfFCUiC0Vko4jsnDV/ioioiPT1pu/3pg/LWGZfEdGM6ZSIXJAxfbWILBCRJhFZIiKPefNnevOaRGSziLRkTF+do4zXisiDld/6wkRktoicl2P+xSIyqdrl8fLeM6Oumrz/SXPG9JAoymXiwwK/8WsBcEZ6QkQOBLrmWG4VcL2fFYrIOcBZwDGq2g0YBLwKoKr7q2o3b/7rwEXpaVX9dXmbUlEjgbNzzD/L+6zqVHVxRl1182YflDHv9ew0ItKpysU0EbLAb/z6C+0D3DnAAzmWGwkMFJGv+ljnF4GXVHUegKouV9URZZc0i4js5x1prPGOJL6V8dkJIvK2iKwXkaUi8j/e/J1F5HkvzSoReV1Ecn1f/gIcKSJ7ZeYHDAQe8aaHisgsL4/5IvLDAmVVEdk3Y/p+Ebk+Y/ok70hrjYj8Q0QGBqyTB0XkNhEZLSLNwBAR2VZEbhaR90TkAxG5XUS29ZY/xjvyu1xEPhSR90Xk7Iz17eLV1zoRmQDsHaRcpjos8Bu/JgA9vCDaCTgdyNW1sgH4NfArn+s8W0QuE5FBYbQ6RaQL8BzwMtAb+H/AQyLS31vkXuCHqtodOAB4zZt/KbAE2AVoAK4GOoxvoqpLgLG4Fn7a2cAoVf3Im14BnAT0AIYCt4jIFwJsyxeA+4AfAjsBdwHPisg2pa7L833gF0B34J/ATbiAPRDoB/QFfpax/O64o7zPAD8C7hCRHt5ndwDrgV2BYUCH7i8THxb4TSnSrf6vA7OBpXmWuwvYU0SOL7QyVX0QF4i/AYwDVojIlZUrLgBHAN2AG1R1o6q+BjxPW7fVJmCAiPRQ1dWq+lbG/D7AXqq6SVVf1/wDW43EC/zeUcGZZHTzqOoLqjpPnXG4H6Eg/ew/AO5S1YmqullVRwKfeNsYxNOq+k9V3YLb3guAn3j1sA74DfC9jOVbgOu9+njWy/tz3o/rKcA1qrpBVafh9hUTUxb4TSn+gmslnkvubh4AVPUT4JfenxRaoao+pKrHADvgWpHXicg3KlVgXOv0PS+4pS0CdvPenwqcACwSkXEi8iVv/o3AXOBlr3um0A/SU0AfETkCaAS2A15Ifygix4vIBK/LaI2X384511TYXsClXjfPGm9de3jbGMR7Ge93BbYBpmas+3ncUVLaR6q6OWN6A+5HtQHolLW+RQHLZKrAAr/xTVUX4U7ynoALdoX8GegJfNvnujep6hPANFyXS6W8D+yR1T+/J97Riqq+qaon4wLc34DHvfnrVfVSVd0H+CZwiYgcnafsG4C/4o6GzgIeVdWNAF43zJO4bpQGVd0BGEX+H8QNuB+OtF0z3r8H/EpVd8j4205VH/FbGdlFz3j/AbAR6J+x7p6q2tPHej4AtuB+hNL2DFgmUwUW+E2pzgeOUtXmQgupaitwLXBFvmVE5FwROVFEuovIVl7X0P7AxIBl28o7QZn+28ZbVzNwuYh0EZFGXCB/VES2FpEzRaSnqm4C1gGbvbKdJO5SVMmYvzlnrs5I3HmPU2l/Nc/WuJb0h0Crt43HFljPFOD7ItJJRI4DMk+S3w38SEQOF2f7dP35rJ+8vJb8PcCt3olaEZHdRaRQWdNpN+F+NH8hIl1F5ADan/MwMWOB35TE66v2e336I8CyAp+vw500XQysAX4H/FhV3whYvDOAjzP+5nkt728BxwMfAbcDZ6vqbC/NWcBCEVmH62r6T29+P2AM0IQ78Xm7qqYK5D0eWAssVdU30zNVdT3w37gjidW4rrJnC6znYtwP0xrcuYK/ZaxrEq6f/0/euubiut0q5VJcF82/cNvyMq4e/Pgx0AvX+r8Xd8RnYkrsQSzGGJMs1uI3xpiEscBvjDEJY4HfGGMSJrTALyJ7iMhY71b1mSJysTf/Wu/W+Cne3wlhlcEYY0xHoZ3cFZE+QB9Vfcu73Gwy7u6+/wCaVPUmv+vaeeedtW/fvoHK0dzczPbbbx8obVJYHRVm9VOc1VFhUdXP5MmTP1LVXbLndw4rQ1Vdhncpn6quF5FZtN0tWZK+ffsyaVKwEW5TqRSNjY2B0iaF1VFhVj/FWR0VFlX9iEjOO6ircjmnuPHax+PuyLwEd+3xOmAScKmqrs6RZhhusCcaGhoOffTRRwPl3dTURLdu3YovmGBWR4VZ/RRndVRYVPXzta99bbKqDsqeH3rgF5FuuAG4fqWqT4lIA+5GGsWN5dJHVQuO5Ddo0CC1Fn94rI4Ks/opzuqosAhb/DkDf6hX9Xij9j0JPKSqTwGo6gfeyIJbcLegH1ZoHcYYYyorzKt6BHfr9ixVvTljfp+Mxb4NzAirDMYYYzoK7eQuMBg3Dsp0EZnizbsaOENEDsZ19SzEPVTCGGNMlYR5Vc8b5B56dlRYeRpjjCnO7tw1xpiEscBvjDERGj0aFi6sbp4W+I0xpgybNsGPfwzLCj15ooDjj4fPf76yZSrGAr8xJvE2b4a5c4OlfeEFuPNOuPDC4Pl/8knwtEFY4DfGJN4vfgH9+sG77wZfRy0908oCvzGmLrS0wKpVwdKOH+9ely6tXHnizAK/MaYuHHkk7LRT1KWoDRb4jTF1YfLkqEtQOyzwG2Ni4/774bnnoi5F/QtzyAZjjCnJ0KHutZZOlNYia/EbY0zCWOA3xlRMayt07w4jR0ZdElOIBX5jTMU0Nbm/iy+OuiTVV0vdUxb4jTGmDJJrDOKYs8BvjGln9mwXzGbPjrok1VdLrfZyWOA3xrTz6KPtX5MgTq32m26CsWPDzcMu5zTGmBi57DL3GubRh7X4jTGmwlpb491tZIHfmDp03XWu+2LjxqhLkjxLl0KXLnD33VGXJD8L/MbUoZtucq8tLdGWI4nSQzs//HC05SjEAr8xpuLi3M3hx5YtMGdO1KUIjwV+Y0zFxOnqmHL87nfucYhTpkRdknBY4Dcmpj78EN57L+pSJNM//uFeFy/2n6aWjnIs8BsTU717w557Rl2K2jVrFjz2WGlpggTvWjzKsev4jTF1acAA93r66cWXrcXgXQ5r8RtjYmvZMlixIupS1B9r8RtjYuszn3GvtdR/nhbnMluL3xgTGlW48EJ4442oS1I9tdBtZIHfmBAtXw7NzdXPt9KtzX/8I/g677gDhgypbHlqgbX4jUmoPn3gi1+MLv9KtD6few4GD3YB3K84B72wWYvfGMOsWVGXAKZOhXPPdXeklmrBAvfqZ3z+Wgh6xgK/MTVj3brgV7icfLJ7Dm4pNySZ+mVX9RhTI/bZB1auTHY3SpzV0v8ltBa/iOwhImNFZJaIzBSRi735O4rIKyLyrvfaK6wyGBM348fDO+8ES7tyZWXLYjpKB+9Sgni+7q04/xCE2dXTClyqqvsBRwD/JSIDgCuBV1W1H/CqN21MInz1q9C/f9SlMNnyBe8g5yxq4TxHaIFfVZep6lve+/XALGA34GRgpLfYSOCUsMpg6tcDD8ARRwRLqwrz5vlffunSrmze7N5v2QKXXALz5wfL25g4qEofv4j0BQ4BJgINqroM3I+DiPTOk2YYMAygoaGBVCoVKO+mpqbAaZOiFuvonHMaAQKV+7nn+nDzzf354x/f4oAD1hVcdsmSrpx11uGMHr2I889fwLx523PLLV/kuefWc/fdk33kll3OUsodPO3mzUcCnXn99dfZbrvNtLQcAWzLhAkTWLiw8NNZFi7sC/Rl4cKFpFILeffd3YB+LFmyhFRqbs406X2oubkTMITNm1tJpd7wujv8lzuq+lq9+iCgF1OmTKFTpzWsXHkAsDPTp0+ne/fCfWzTp+8EHMjKlR+RSs1g2rSewCGsXbuGVMqN61z4Oxa83IGpaqh/QDdgMvAdb3pN1ueri63j0EMP1aDGjh0bOG1SRFVH11yjevXVwdK6dnuwtOee69Led1/xZceNc8sOGeKmp0xx0wMHBitnKeUuJ223bm7Zdevc9F57uekFC4qnHT7cLTt8uJv+wx/c9EUX5U+T3ofWrnXLdu/u5m/ZUr1tLiftUUe5ZceMcdMnneSmn322eNpnn3XLnnSSmx4/3k0feWTbMoW+Y+WUuxhgkuaIqaFezikiXYAngYdU9Slv9gci0sf7vA9gQzAl1C9/Cb/+ddSlqE9hnFgsZZ1xPrFZLXGugzCv6hHgXmCWqt6c8dGzwDne+3OAZ8IqgzFJlz7RmA5CYZ+srIUTm36UE7RroQ7C7OMfDJwFTBeR9APMrgZuAB4XkfOBxcB3QyyDMYbyAn+SlVNfcW7xhxb4VfUNIF+1HR1WvsYYE6Va+HG1IRtMWdavh9bWqEtR2IoV7hLMuJfT1LY4t/CzWeA3ZenRw9+j7aJ00UVwyy3wwgtRl6S21VJgCyopz9y1wG/K9tRTxZeJ0saN7jUJgSsM9drPnakWg3c5LPAbY0zCWOA3xpgsYR6pLFsGjz8e3vr9sMBvasKIEdDYGHUpale1L+eslS6eYsKor2OOcefFmpoqv26/bDz+hNu4Ef7wh3054ADYeeeoS5PfD38YPG3Ud7FGIbt8lQj8frY5aX3luWTfNJftvffca5CnoVWKBf6Ee+IJePrp3enRA+6/P+rShKOSrd1aC2xJ3OaoFQv8cWBdPRHZsiUe15VnDjcctpdegnHjws8nn0oEsDh/mcOW5G3Pdt118KMfRV2K4CzwR+TLX4YuXYKlbWmB6dMrW55qOO64+umnT1IrOEnb6tfw4XDXXe3n1dIPowX+Mlx9NTz8cLC0EycGz3fYMBg4sO3B25s3w9Kl/tJu2uRaK83NwfI+4AB48MFgaY2JO7uByxT1m9/AmWdWP9833nCv6asCrrkGdt8dliwpnvb++11r5brrguU9cyacdVawtMbEVRTBO8ojBAv8dWD0aPe6wseTDVq8hy9t2BBeeeKmlg7BTfU8+CD8+9/VzzcORwh2VY9JjDh84aJiP34dpY9cw6qbONe5tfgTLs47Z6UkYRuLsRu4SlPvD2KxwG+A2thZy5WEbSymnCdwJfEGrnrbnjQL/DFx881wyilRl8LUi0q2uGvhhqRKq8S2xrm+LPDHxKWXwjP29OFQxPkLGLZ6bbGC+7/ecQesWRNeHmE+o7jYfvnJJ6Xn7ZcF/jqQ5MBWinoOgkk0cSJceCH84AdRl6Q0fvfDM84IrwwW+OuIBbbqsR9bf8Ksp48/dq8ffRReHqWo9LY+/XRl15fJAr+pe2H0d5v6VMk7d//1L5g9u7zyhMUCf5WIwP/+b9Sl6ChJLdckBe0k/V8rIax9I3s8n7iwwF9Fv/xl1CXIL0lBMUmyr8iJ2/Nz58yBr3412oeSFHLDDaVvdy18lyzw1yBrzZWmkvVVq3VfTuAPksZvPV1xBYwfD2PGlJ5HqXkFMX5824NT6okF/hoWVsvi44/bxvSpJ5Wsr1po1VVa3G7g8pvXunXl5RPWsypskLYItbRU7h+wYgWsXVuZdZUiV/nHjYOVK4Otb7vt3GifQWzeXJ8/GklW6z9yPXtGXYL24lCfiQ78K1dC167w298WX3bLFrjppsJ9kQ0NsOeelStfqdI7VGure+DJsccGX1fQH41vfcvV6Ysvtl1uF7Va7Z4pRzW3ef58mDhxx+plaMqW6MC/bJl79fNgkWeegcsuc3+FlHtYWQnpL/20aeWtZ/Dg0k+6jRrlXk84AS6+uLS006fD4YeHd6IvDi2taqvGNvfvD1deOTDUPGrpedCl1Hn62RrVlujAX4p06zWKrpyo/OMf8OqrwdO/+25py19+ubv2+Ywz4O9/Ly2tqrsCI9eRShJb/NXk99nRhZ4BUex/NHSo//JUWjn7T6G0qjBkSPB1l8MCfw0YMgQOO6z0dK2tLpAWEseg+PzzcOSRpaUZNw6uugp++MP8y9RLi/+DD4Kn7dMn9/zly+HDDwunveceeOed4HkPG9ZxXiX+J2Hsw37XOWsWnHhi+zSVGqsnTPYglhpQzuHg4YfH72qMMGzc6F7j0NUWtl13LT1oFFs+/YOQa7nMfeONN+Bznyst77QZM4Kly6dS+2xLi+tmhNLr9cUXg+drV/VErJR/QLX+Warw5JPuKpk4aG0Nvu3z5wcfQXHTprag7scrr8C++5aeT0tLaXXtpy4eeST/Z3PmFE7r5/nJ2ebNy39CvdpBJo5Hkvn84AfuiCdsGzfCvffGo24SHfhLaTFUu0X84INw2mnQOQbHZEuXQpcuMGJEsPSf/SwceGCwtPvtB9tsU1qaefPc6zPPuHz9BPSuXeGkk9rPW7zY3VWaqZT94Pvfz//Z/vsXTrvHHv7zARdM9t0XvvMduPvu4EP6bt7sutr85rlqVft5pdTPk08GL+e0ae3P5zz8sP+0Cxa0P//0+usdl8kXnOfNC36i+de/hgsuiMd5wtDCiojcB5wErFDVA7x51wI/ANK9iVer6qiwylDLcvXjTp0KBx3UcX6xFsSYMfD1r8PChcHKkv6SFGrBFhOkBQttQTyIoUNh9eq2LoZiQSn90HqASZPgi1/Mv+z06a4Ft/XWwcoW1pHc6NHtt6NUN9wAkyf7W/amm9wJ+bT166FHD/e+2L0cr73mGjaZGhr8lzP7e3Dmmf7T7rOP/2Wh/fdr0KDgR6/FzqFUU5gt/vuB43LMv0VVD/b+ai7oP/ooTJkSPH3QAAhw8MGFP88X2O65x7327RsskMalu6lcflqjK1a4Vz+t3muvLas4OU2ZUt2ugOuvb/8DV8r+8eyz7acXLCi8fOZ2ZR8pqLbVfZxV8qEvddnHr6rjgVVFF6xBhxwSPG2ph/DZWlqCt9yh9Gv7ly+HY44Jnl8pqt2dNnJkx3kNDf67H5YuzT1/06Zg2/LCC27fuu++0tMGdc017uimkE2bqlOWoKIMoOXknf3jV02+unpEZC+gn6qOEZGuQGdVXR8wz4tE5GxgEnCpqq7Ok+cwYBhAQ0MDqVQqUGZNTU150y5YsB1wGM3NzaRSbxZcz9tv9wYGfDrt1tmY8Z4c05kaS0o7b94ewGc7rOWYYz4CdgZgwoQJLFrUQlPTIKAbb775JqtXN9PaKkBb5/SKFSuA3gCsWbMa6MXSpUtIpeYya9auwOdZvnwZqVT6jGNbWceNWwzs6aVdA+xQZJvb0q5Zs5rHHpsNfKndNuRLu2rVgcBOWcu1ra9Q2mnTegEHtVuutXUw0OXTeVOnTqVLl9UsX94f6MO4cXD//f+ib98N7fIZM+Z1Fi7cA+j76by1a9eQSk1h3rztAddEXr58OanUbMaP35mmps6ccII7Q9jU1Blofz1qrvrJ3k9Gjdod2JfRo98D9sixXO60xx8/hL59m4EeZBs/fjxbb72FDz/Ml29ju+WXLVsGuEt8Fi5cSCq1kAsvbFtm9uzZpFJuO9euPZj0/gDw5ptvkq6bdD7Tp/cEXEvJfRfdr8zMmbsAbSc6ZsyYARzge5sz569d27ZflpoWoKWlBdgWcPvINtusZtWqgYC7G3nChAksXtySM+2oUR8Aro9q1aqVpFLTmTOnGzAIgCVL3PesqamJpUuXArt9mvbss1fScX8vVO4KUtWCf7g++TeBed50P+DVYum8ZfsCMzKmG4BOuCONXwH3+VnPoYceqkGNHTs272czZ6qC6n77FV/PI4+4ZdN/11/f9j4tezpTZtqXXiqe9sYb26dJ/3Xu3PZ+wQK37MCBbnrKFDe9cWP7NKef3vb+a19zrxdd5Ja95x43fd55uct6xRVt73v3Ll7uzLSNjbm3IV/a44/vuFyxtIMHu+mXX+64XK9e7ee9/LKbf+65bfPeeqtjPmvXqg4f3n7ekCFuuSlT2uadfXb7tPfco9raqrp6dfFyZ+8nf/mL6v/8j5v/k5+UljZXHaf/WlpKSzt0aNv74cM7LnPvvW1pjzyy/WdTp3bMJ/N7MnBgW9onnmi/7JNPdky7aZO/cg8ZUl597bln2/vRo90yxx7bNm/ePH91fdxxbpnJk9vmXXyxmzd27Fi98MLC349i5Q4CmKTaMab6afH/F3AYMNH7oXhXRHoH/JH59JSliNwN+Lx+IH5+/nN/y6m68WsyfeMbwfP1e5dkPmPHBk9b7T5YP/3spd7h65dq6WkuuMB1xZVyohFcv/FZZ7VN+xlCJCpB6iWoap1bWry48OfV3OZq8dPH/4mqfnoltYh0BgJVhYhk3jf4baDCt3TEk9/L48KyaFHwtEEvt4Py++y/+c3gaWfMcFf0BC1P9pfd70m9hQvdXcS55PvhzA5wcXmGbC7lBMFCaeMSXMPavkrnVS4/Lf5xInI10FVEvg5cCDxXLJGIPILrrNpZRJYAw4FGETkY98OxEChwg33t27w53Ic4+H260oQJwfO49dbgaf0q57LIfI46quO8Um6lnzix4zw/brrJ/eWSq2U5bVp8H89nwpUeJDIKfgL/lcD5wHRcoB4F3FMskaqekWP2vSWVrkpmzXJXaOy2W8fPWluDd69cdRXceGN5ZfOjWOCPit9gOXCgeyh1JctfTmvqr3+Fl1/O/Vmlux+CjIBaj8oZwjuMlvPMmZVfZ7Zyxj0qV9GuHlXdoqp3q+p3VfU0731MDszKkxlo8j14ZMgQd1dnoaCU72aVV14JXrZ64Pea8GLDF/hRyR+NQl/IX/2qcvlAeedsNmyAq6+uXFnK1dwcPG3chl3Od6muH7UQHYu2+EVkATn69FW1xPvfapOfbpKuXSv/z87uaqhFpYyxU03l/K+ibKVlu/FG+M1vgqX95BPYdtvged96a8fBA889t3CadL0vXlxb+3ep+8udd+ZO62c91RrOwU9Xz6CM99sC3yV9gasJTbUCTC20ToIIa7syjyyi7lor5xGX2Se+0/zeHPjTn3ac53ef3Wsvf8vlsmhRdc47laOcizmq9YNYNPCravajLW4VkTeA/w2nSCYKUQexSsv1QJb0Nhbrgqvmj2Hcnk9czuW+ufitS7/Lff/77gFBmfw+DH39+o6XVieVn66eL2RMboU7AugeWomqKFewe/11NyZO9+7Fly3Gz5g+K1bkbn35HVrh3Xc7jnNe6ElHxZQzkFS59xiMqtLITe+/X/jzJ57wt556PVoqpJrbnCuvXCfXs38I8nnhBSjnRtiXXgqeNm78dPX8PuN9K+4yzP8IpTQR++gj+MpX3BN1Sj1cC9piPvHE4mOlFJLroRjH5Roaz6dLLgmWbvXqaPu/v/714svk+h/lmlfOWEhxU+kjubACfzknU6vF7/cqX53H6ajaT1fP16pRkDhIt5TTre03M4bv8Xs4Wapygn629I5VznX7QVvtp53mxhuPu7lz20+r+h8sa9mytic1xUGcAokfhX40KnFlV1gq0V21YMF2sdp38gZ+ESnY9lPVmytfnHjJDMpn5LorIQSrV0OvXsHSXncd3HGH/+Xfequ8h6lnqmZrP98NUn7069dx3skn+0vbv3/wfF97DY4+Onj6cobzzqXWfjSqJawjmvPOK/7Q7JkzK/94ynwKtfjroh+/1uy4o3tUoR/ZX94nnijtC33oof6Xzfboo/Df/x0s7YwZwZ/I1dQEl10WLG0+fn+01ucYj9ZvK66co6G33y7+xK64qvQPTD3/YB1wQPFlKiVv4FfVX1SvGNGI605U7IEWhZRzE00pzjuv+N2W+er3b38Lnm85LbIw/t/PFR28JD+/3Yd+GwL5BN3usLo3o1Kt73tc40omP1f1bIsbsmF/0oNWA6p6XojlMlV2772l3QxUzi32xilnADwIfvOWX+V2TyXRZz9b/KqxOPAzOudfgF2BbwDjgN2BoA9hMTGR63rt3oEG226T3dJZvry89VVaOS2xfDc81So/w1lv2QKNjcHzaG52YzCllXq0FpeWcynlLvforFr8BP59VfUaoFlVRwInAgF7aKM3b57boXLt+HvvXf3ylOOGGzrO87uTVnoQqmp9SaO6dj7X5YZxCUxBnHpqsHSl1P8pp1T+2QLVqPM4XX0TFj+BP/3EzTUicgDQk8xn0tWYMWPc6wMPwG23tf+sUn2a1TozX8oVPHFSywHT+B+hNP1dC2LGjPLGEsrFz37397+70WIrqZIPaK8UPzdwjRCRXsA1wLNAN+99zfvjH8NZ74EHJvOuzriL8gdn3brgaaMqd658VeGXvww/73IfOP/ii8HS5euqKef7PGBA8WWqzU/g/7Oqbsb17ydiRM60OH3h/KrW4+qylfLAGb+PrawGker8n3MNoxH3I5985QvrcZd++LmrevZsOOGEyua7lZ++kTyifOBKPn42Z4GIjBCRo0Xivqv6N2JE/s+i3sqo8w+qGuWuxoNt/LKjutJUor78XAn13e/mnh/0Kii/5c41DHlc9xE/gb8/MAb30PWFIvInETky3GKFx09wyn6kYS2pxTKX4vrrg6ctZ/A6U135Bgv08/3NdTXZihX+Bk0s5/tTzgBw1ebnCVwfq+rjqvod4GCgB67bx5iacumlHeeV+0PpN32+/vKgaashjHwXLfK3XK6rgebPzz3cth9+L9yo94ZTmq+eKxH5qojcDryFu4mrJkfnXLs2vBO6Jv5WrKjs+p58srwBvPw+NjFXAH76aX9pyxHGKJPlXPFWqHvWlMbvoxenAI8Dl6lqlQYFqLyhQ/3veLNmJefXPw7KqevJk/0tlytg/fjHwfNuboY//zlYWnB3Swf1ne8ET/vWW8HTliuqMe39/o9fey3ccsSFn6t6DlLVMi5Giw+/t1IvWuQuwdp330vC+VEAAA/LSURBVHDLU2/KaQn++9/B0w4aVHyZfCZOhG7dgqeP4xUbxZQzOF85P9Cq8T/iLudBRLXETx9/XQT9ILLHbq+WWr2qpxzlBKN6F6c+/ldeKf7oynzKvZHJ79H6pk3FlylFPR75l3F1qglLrQb+ckaqrIZ89drUFHydfgerK2dAtmo9gDtbrgBazrmFcsdueuEFf8utXdtxXrk3hNUbC/ymYq67LuoSFBblD2quo8dc4/vncu21wfN96qngaf/5z+Bp4yZONw3GQdHALyIXi0gPce4VkbdE5NhqFM6UrtzDUr/BqBZ98EHUJai+aj05rp7F/bxEEH5a/Od5/fzHArsAQ4Ec40KaTL/7XTT5Bu1/TfN7OG1MUtx+e9QlqDw/gT99gHwCbtyeqRnzakZLS9tD1KvhiiuCp7X+SGNMmPwE/ski8jIu8L8kIt2Bmnso2/nn185To0aOjLoExphKiGs3kZ/r+M/HDdUwX1U3iMiOuO6emhLliILGGBMnflr8XwLmqOoaEflP4OdAjgum4mvTJv9jhBhjTL3zE/jvADaIyEHA5cAi4IFQS1Vh99wTdQmMMSY+/AT+VlVV4GTg/1T1/4Du4RarspprdnQhY0ySXXJJeTf/5eMn8K8XkauAs4AXRKQT0KVYIhG5T0RWiMiMjHk7isgrIvKu99oreNGNMaa+3XKLez54pfkJ/KcDn+Cu518O7Ab4eQ7S/cBxWfOuBF5V1X7Aq960McaYPMJ4nKqfQdqWAw8BPUXkJKBFVYv+BqnqeGBV1uyTgfTFiiOBU0orbjC1OvaNMcaEwc94/P+Ba+GncDdu/VFELlPVvwbIr0FVlwGo6jIR6V0g32HAMICGhgZSAZ9r1tTUxLx5cwEbY9kYU3veeecdUimfY8r75Oc6/p8BX1TVFQAisgvuGbxBAr9vqjoCGAEwaNAgbWxsDLSeVCrFvjawvjGmRn3uc5+jsfFzFV2nnz7+rdJB37PSZ7pcPhCRPgDea4UfhmeMMfUljK5qPwF8tIi8JCLnisi5wAvAqID5PQuc470/B3gm4HqMMcYEVLSrR1UvE5FTgcG4Pv4Rqlr0cQwi8gjQCOwsIkuA4bhRPR8XkfOBxcB3yyi7b3Zy1xhj2vjp40dVnwSeLGXFqppvJPCjS1lPJVjgN8aYNnkDv4isB3I91kMAVdUeoZXKGGMMEE7DNW/gV9WaGpahkI0boy6BMcYEE9XJ3Zq3YUPUJTDGmPhIROA3xhjTJhGB307uGmNMm0QEfmOMMW3qOvD//vdw5ZUHRl0MY4wJrKpX9dSD+fNh9uzu7LRT1CUxxpj4qOsWP4CqMCroABPGGFOH6jrw20ldY0yts+v4jTEmYSzwl8ha/MYY01FdB34AzTXakDHGJFhdB35r8RtjTEd1HfiNMcZ0VPeB37p6jDG1zE7ulsi6eowxpqO6DvzgbuAyxhjTpq4Dv7X4jTGmo7oO/MYYU+usj79E1uI3xtQ6C/wB2FU9xhjTXl0HfhHYsKGuR542xpiS1XXgN8YY05EFfmOMSZi6Dvx2ctcYU+vs5K4xxpiy1XXgtxa/McZ0VNeB3xhjap119ZTIWvzGmFpngd8YY0zZ6jrwW4vfGGM6quvAb4wxpqNIxjMQkYXAemAz0Kqqg6IohzHGJFGUA9l8TVU/CjMD6+oxxtQ6O7lrjDGmbFEFfgVeFpHJIjIsojIYY0wiRdXVM1hV3xeR3sArIjJbVcdnLuD9IAwDaGhoIJVKlZzJ/PmfBfaoQHGNMSYas2a9TSq1oqLrjCTwq+r73usKEXkaOAwYn7XMCGAEwKBBg7SxsbHkfJ57ruyiGmNMpAYMGEBj44CKrrPqXT0isr2IdE+/B44FZoSR11Z2BsMYU+PCOLkbRYu/AXha3NZ0Bh5W1dFhZPTee2Gs1RhjalvVA7+qzgcOqkZejz1WjVyMMaa2WGeIMcYkjAV+Y4yJMbuByxhjEmbevMqv0wK/McbE2Lp1lV+nBX5jjImxMC5Lt8BvjDExZoHfGGMSxgK/McYkjAV+Y4xJmHfeqfw6LfAbY0yMrajswJyABX5jjIk16+oxxpiEGTOm8uu0wG+MMQljgd8YYxLGAr8xxiSMBX5jjEkYC/zGGJMwFviNMSZhLPAbY0zCWOA3xpiEscBvjDEJY4HfGGMSxgK/McYkjAV+Y4xJGAv8xhiTMBb4jTEmYSzwG2NMwtR14N9vv6hLYIwx8VPXgf/556MugTHGxE9dB/5dd426BMYYEz91Hfi32y7qEhhjTHmWLav8OjtXfpXGxNNBB8HUqcHSXn45PPUUzJ0L++8PM2f6T/vEEzBrlkt/+OGwyy7wpz/B4MGwZIkr1wMPtC1/4onQty/cdhuMHg2dOsFLL7m0228P48bBttvC7Nlw1FHw29/C/PluuYsugn79XF7Dh8M++8D48e61Z094/32XZ3Ozy2P2bLj+ethpJ/jpT+HLX3bPeO3fH444ApYuhW22gd69YdUqWLQIdtgB1q+HvfeG22+Hl1+GYcMmc+qphzJ3rkvzla9A586wbp1bN0BTE3TtCsuXQ0ODq5Mbb4Rbb3UPFO/a1a3rK19xddTaCiKuAdfc7F43bICNG92677wTTj0VevVyZRo1yp3X23NP6NIFNm92y33yCWy9tVvX2rVu3uzZsOOOsNdeLu9p09zyhxzS/n+3ZYtLJwIff+zy32ort1177eWW+fBDePttV26R3PvAa6+l+PznG9l1V1i82NU9uPXNmuXKXc2Gqqhq9XILaNCgQTpp0qRAaV99NcUxxzTm/Ozee+G446B7dze9/fbun9+lS8CC1qhUKkVjY2PUxYgtq5/irI4Ki6p+RGSyqg7Knl/3Lf5OnaCU37at6rrzyxhjIurjF5HjRGSOiMwVkSujKIMxxiRV1QO/iHQCbgOOBwYAZ4jIgGqXwxhjkiqKFv9hwFxVna+qG4FHgZMjKIcxxiRSFH38uwHvZUwvAQ7PXkhEhgHDABoaGkilUoEya2pqCpw2KayOCrP6Kc7qqLC41U8UgT/XBU8dTr+q6ghgBLireoKeEberDYqzOirM6qc4q6PC4lY/UXT1LAH2yJjeHXg/gnIYY0wiRRH43wT6icjeIrI18D3g2QjKYYwxiVT1rh5VbRWRi4CXgE7Afapawn2QxhhjylETd+6KyIfAooDJdwY+qmBx6pHVUWFWP8VZHRUWVf3spaq7ZM+sicBfDhGZlOuWZdPG6qgwq5/irI4Ki1v92AAFxhiTMBb4jTEmYZIQ+EdEXYAaYHVUmNVPcVZHhcWqfuq+j98YY0x7SWjxG2OMyWCB3xhjEqauA3+9j/svInuIyFgRmSUiM0XkYm/+jiLyioi867328uaLiPzBq49pIvKFjHWd4y3/roickzH/UBGZ7qX5g4h7uFy+POJIRDqJyL9F5Hlvem8RmeiV/THvDnJEZBtveq73ed+MdVzlzZ8jIt/ImJ9zH8uXRxyJyA4i8lcRme3tS1+yfaiNiPzU+37NEJFHRGTbmt+HVLUu/3B3Bc8D9gG2BqYCA6IuV4W3sQ/wBe99d+Ad3DMOfgdc6c2/Evit9/4E4EXcQHlHABO9+TsC873XXt77Xt5n/wK+5KV5ETjem58zjzj+AZcADwPPe9OPA9/z3t8J/Nh7fyFwp/f+e8Bj3vsB3v6zDbC3t191KrSP5csjjn/ASOAC7/3WwA62D31aN7sBC4CuGf/Xc2t9H4q8YkP8h30JeClj+irgqqjLFfI2PwN8HZgD9PHm9QHmeO/vAs7IWH6O9/kZwF0Z8+/y5vUBZmfM/3S5fHnE7Q83COCrwFHA817w+QjonL2f4IYR+ZL3vrO3nGTvO+nl8u1jhfKI2x/QwwtskjXf9iH9NPC/h/tB6+ztQ9+o9X2onrt6co37v1tEZQmdd0h5CDARaFDVZQDea29vsXx1Umj+khzzKZBH3NwKXA5s8aZ3Ataoaqs3nblNn9aD9/lab/lS661QHnGzD/Ah8GevO+weEdke24cAUNWlwE3AYmAZbp+YTI3vQ/Uc+H2N+18PRKQb8CTwE1VdV2jRHPM0wPyaICInAStUdXLm7ByLapHP6rneOgNfAO5Q1UOAZly3Sz71XBcdeOcdTsZ1z3wG2B732NhsNbUP1XPgT8S4/yLSBRf0H1LVp7zZH4hIH+/zPsAKb36+Oik0f/cc8wvlESeDgW+JyELcIz6Pwh0B7CAi6ZFpM7fp03rwPu8JrKL0evuoQB5xswRYoqoTvem/4n4IbB9yjgEWqOqHqroJeAr4MjW+D9Vz4K/7cf+9qyPuBWap6s0ZHz0LpK+qOAfX95+ef7Z3ZcYRwFrvEPsl4FgR6eW1cI7F9ScuA9aLyBFeXmdnrStXHrGhqlep6u6q2hf3/39NVc8ExgKneYtl1096m07zlldv/ve8Kzb2BvrhTljm3Me8NPnyiBVVXQ68JyL9vVlHA29j+1DaYuAIEdnOK3+6fmp7H4r65EnIJ2ZOwF3pMg/4WdTlCWH7jsQd/k0Dpnh/J+D6B18F3vVed/SWF+A2rz6mA4My1nUeMNf7G5oxfxAww0vzJ9ru9s6ZR1z/gEbarurZB/elmws8AWzjzd/Wm57rfb5PRvqfeXUwB++qlEL7WL484vgHHAxM8vajv+GuyrF9qK38vwBme9vwF9yVOTW9D9mQDcYYkzD13NVjjDEmBwv8xhiTMBb4jTEmYSzwG2NMwljgN8aYhLHAb0wIRKRRvNFAjYkbC/zGGJMwFvhNoonIf4rIv0RkiojcJW7s/iYR+b2IvCUir4rILt6yB4vIBG8c+qelbYz6fUVkjIhM9dJ81lt9N2kb5/6hjHHobxCRt7313BTRppsEs8BvEktE9gNOBwar6sHAZuBM3EBcb6nqF4BxwHAvyQPAFao6EHfXanr+Q8BtqnoQbhyXZd78Q4Cf4MZi3wcYLCI7At8G9vfWc324W2lMRxb4TZIdDRwKvCkiU7zpfXBDOD/mLfMgcKSI9AR2UNVx3vyRwFdEpDuwm6o+DaCqLaq6wVvmX6q6RFW34IbT6AusA1qAe0TkO0B6WWOqxgK/STIBRqrqwd5ff1W9NsdyhcY1yTV8btonGe834x6q0QochhtR9RRgdIllNqZsFvhNkr0KnCYiveHTZ8DuhftepEdF/D7whqquBVaLyBBv/lnAOHXPP1giIqd469hGRLbLl6H37ISeqjoK1w10cBgbZkwhnYsvYkx9UtW3ReTnwMsishWwCfgv3MNI9heRybgnKJ3uJTkHuNML7POBod78s4C7ROQ6bx3fLZBtd+AZEdkWd7Tw0wpvljFF2eicxmQRkSZV7RZ1OYwJi3X1GGNMwliL3xhjEsZa/MYYkzAW+I0xJmEs8BtjTMJY4DfGmISxwG+MMQnz/wFmxqztou1s9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실함수 추세 확인\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "plt.plot(loss_val_list, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_loss =  23.999097520509224 , max_loss_index =  821449 , min_loss =  0.5788205409775559 , min_loss_index =  7390\n",
      "epochs_num =  19\n",
      "real_max_index =  23449 , real_min_index =  7390\n"
     ]
    }
   ],
   "source": [
    "max_loss = np.max(loss_val_list)\n",
    "min_loss = np.min(loss_val_list)\n",
    "max_loss_index = np.argmax(loss_val_list)\n",
    "min_loss_index = np.argmin(loss_val_list)\n",
    "\n",
    "print(\"max_loss = \", max_loss, \", max_loss_index = \", max_loss_index, \", min_loss = \", min_loss, \", min_loss_index = \", min_loss_index)\n",
    "\n",
    "epochs_num = int(max_loss_index/len(training_data))  # \n",
    "print('epochs_num = ', epochs_num)\n",
    "\n",
    "if max_loss_index > len(training_data):\n",
    "    real_max_loss_index = max_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_max_loss_index = max_loss_index\n",
    "    \n",
    "\n",
    "if min_loss_index > len(training_data):\n",
    "    real_min_loss_index = min_loss_index-epochs_num*len(training_data)\n",
    "else:\n",
    "    real_min_loss_index = min_loss_index\n",
    "    \n",
    "\n",
    "\n",
    "print('real_max_index = ', real_max_loss_index, ', real_min_index = ', real_min_loss_index)  # real_min_loss_index 다시 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  4\n",
      "prediction =  7\n"
     ]
    }
   ],
   "source": [
    "# check max loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_max_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_max_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_max_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  8\n",
      "prediction =  8\n"
     ]
    }
   ],
   "source": [
    "# check min loss data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = training_data[real_min_loss_index, 1:].reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "target = int(training_data[real_min_loss_index, 0])\n",
    "\n",
    "input_data = (training_data[real_min_loss_index, 1:] / 255.0 * 0.99) + 0.01\n",
    "\n",
    "predicted_num = nn.predict(np.array(input_data, ndmin=2))\n",
    "\n",
    "print('label = ', target)\n",
    "print('prediction = ', predicted_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
