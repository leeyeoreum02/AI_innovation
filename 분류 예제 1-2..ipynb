{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTest:\n",
    "    def __init__(self, x_data, t_data, learning_rate, iteration_count):\n",
    "        self.x_data = x_data\n",
    "        self.t_data = t_data\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.x_data.shape[1], 1)\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        self.loss_val_list = []\n",
    "        \n",
    "        print(\"ClassificationTest Object is created.\\n\")\n",
    "        \n",
    "    def get_W_b(self):\n",
    "        return self.W, self.b\n",
    "        \n",
    "    def __loss_func(self):\n",
    "        z = np.dot(self.x_data, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "    \n",
    "        return (np.sum((self.t_data - y)**2)) / (len(self.x_data))    \n",
    "    # 손실함수 값 계산 함수\n",
    "    # 입력변수 x, t : numpy type\n",
    "    def __loss_val(self):\n",
    "        z = np.dot(self.x_data, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "    \n",
    "        return (np.sum((self.t_data - y)**2)) / (len(self.x_data))    \n",
    "\n",
    "    def train(self):\n",
    "        f = lambda x : self.__loss_func()\n",
    "        \n",
    "        print(\"Initial error value = \", self.__loss_val() , \"\\n\", \"Initial W = \", self.W, \"\\n\", \", b = \", self.b)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        for step in range(self.iteration_count):\n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "            \n",
    "            if step % 1000 == 0:\n",
    "                print(\"step = \", step, \"loss value = \", self.__loss_val())\n",
    "                self.loss_val_list.append(self.__loss_val())\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)\n",
    "        \n",
    "    def display_lossval_trend(self):\n",
    "        plt.title('Loss Value Trend')\n",
    "        plt.xlabel('epochs ( X 1000)')\n",
    "        plt.ylabel('loss value')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(self.loss_val_list, ls='--', lw=2, label='lr={}, epoch={}'.format(self.learning_rate, self.iteration_count))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    # 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "    # 입력변수 x : numpy type\n",
    "    def predict(self, test_data):\n",
    "        z = np.dot(test_data, self.W) + self.b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "    \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (10, 1)\n",
      "t_data.ndim =  2 , t_data.shape =  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n",
    "    t_data = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1]).reshape(10, 1)\n",
    "\n",
    "    print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "    print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) \n",
    "\n",
    "except FileNotFoundError as err:\n",
    "    print(str(err))\n",
    "except IndexError as err:\n",
    "    print(str(err))\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationTest Object is created.\n",
      "\n",
      "Initial error value =  11.974518975085063 \n",
      " Initial W =  [[0.5488135]] \n",
      " , b =  [0.71518937]\n",
      "step =  0 loss value =  27.863662731540508\n",
      "step =  1000 loss value =  0.632674094626388\n",
      "step =  2000 loss value =  0.12766853313190404\n",
      "step =  3000 loss value =  0.11895314613766853\n",
      "step =  4000 loss value =  0.11139507245005922\n",
      "step =  5000 loss value =  0.10476729645935566\n",
      "step =  6000 loss value =  0.09890104150691327\n",
      "step =  7000 loss value =  0.09366760947361322\n",
      "step =  8000 loss value =  0.08896677608385663\n",
      "step =  9000 loss value =  0.0847190927748569\n",
      "step =  10000 loss value =  0.08086061637156261\n",
      "step =  11000 loss value =  0.07733920237919427\n",
      "step =  12000 loss value =  0.0741118366806432\n",
      "step =  13000 loss value =  0.07114267544831922\n",
      "step =  14000 loss value =  0.06840157946386861\n",
      "step =  15000 loss value =  0.06586300075713776\n",
      "step =  16000 loss value =  0.06350512493605955\n",
      "step =  17000 loss value =  0.061309202135547844\n",
      "step =  18000 loss value =  0.059259019161046464\n",
      "step =  19000 loss value =  0.05734047873599764\n",
      "step =  20000 loss value =  0.055541260974993525\n",
      "\n",
      "Elapsed Time =>  0:00:08.255835\n"
     ]
    }
   ],
   "source": [
    "obj = ClassificationTest(x_data, t_data, 1e-1, 20001)\n",
    "obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationTest Object is created.\n",
      "\n",
      "Initial error value =  12.515506999781792 \n",
      " Initial W =  [[0.60276338]] \n",
      " , b =  [0.54488318]\n",
      "step =  0 loss value =  9.253782781201112\n",
      "step =  1000 loss value =  1.0769316083698528\n",
      "step =  2000 loss value =  0.786476471453669\n",
      "step =  3000 loss value =  0.6588199487813373\n",
      "step =  4000 loss value =  0.5823921795683434\n",
      "step =  5000 loss value =  0.5297124226684985\n",
      "step =  6000 loss value =  0.4903422413675966\n",
      "step =  7000 loss value =  0.45933357685738835\n",
      "step =  8000 loss value =  0.4339959549639045\n",
      "step =  9000 loss value =  0.412722178461071\n",
      "step =  10000 loss value =  0.3944838720002332\n",
      "step =  11000 loss value =  0.37858756231572505\n",
      "step =  12000 loss value =  0.3645458262988529\n",
      "step =  13000 loss value =  0.35200437141806395\n",
      "step =  14000 loss value =  0.3406984254065923\n",
      "step =  15000 loss value =  0.33042544454442424\n",
      "step =  16000 loss value =  0.3210273739635761\n",
      "step =  17000 loss value =  0.312378739312919\n",
      "step =  18000 loss value =  0.30437842832874745\n",
      "step =  19000 loss value =  0.29694388065674\n",
      "step =  20000 loss value =  0.2900068924533531\n",
      "\n",
      "Elapsed Time =>  0:00:08.635738\n"
     ]
    }
   ],
   "source": [
    "obj1 = ClassificationTest(x_data, t_data, 1e-2, 20001)\n",
    "obj1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationTest Object is created.\n",
      "\n",
      "Initial error value =  9.569460086371842 \n",
      " Initial W =  [[0.4236548]] \n",
      " , b =  [0.64589411]\n",
      "step =  0 loss value =  28.001979769364056\n",
      "step =  1000 loss value =  1.0278362228381723\n",
      "step =  2000 loss value =  0.1276537232001611\n",
      "step =  3000 loss value =  0.11894038150553615\n",
      "step =  4000 loss value =  0.11138393566981791\n",
      "step =  5000 loss value =  0.10475748137152886\n",
      "step =  6000 loss value =  0.09889231726414904\n",
      "step =  7000 loss value =  0.09365979799093706\n",
      "step =  8000 loss value =  0.08895973732121899\n",
      "step =  9000 loss value =  0.08471271479995521\n",
      "step =  10000 loss value =  0.08085480845409061\n",
      "step =  11000 loss value =  0.07733389007094281\n",
      "step =  12000 loss value =  0.07410695823435928\n",
      "step =  13000 loss value =  0.07113817916131165\n",
      "step =  14000 loss value =  0.06839742167473775\n",
      "step =  15000 loss value =  0.06585914431225277\n",
      "step =  16000 loss value =  0.06350153800031756\n",
      "step =  17000 loss value =  0.061305857258907415\n",
      "step =  18000 loss value =  0.059255892538138226\n",
      "step =  19000 loss value =  0.05733754961283853\n",
      "step =  20000 loss value =  0.0555385111696141\n",
      "\n",
      "Elapsed Time =>  0:00:09.714072\n"
     ]
    }
   ],
   "source": [
    "obj2 = ClassificationTest(x_data, t_data, 1e-1, 20001)\n",
    "obj2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationTest Object is created.\n",
      "\n",
      "Initial error value =  11.974518975085063 \n",
      " Initial W =  [[0.5488135]] \n",
      " , b =  [0.71518937]\n",
      "step =  0 loss value =  27.863662731540508\n",
      "step =  1000 loss value =  0.632674094626388\n",
      "step =  2000 loss value =  0.12766853313190404\n",
      "step =  3000 loss value =  0.11895314613766853\n",
      "step =  4000 loss value =  0.11139507245005922\n",
      "step =  5000 loss value =  0.10476729645935566\n",
      "step =  6000 loss value =  0.09890104150691327\n",
      "step =  7000 loss value =  0.09366760947361322\n",
      "step =  8000 loss value =  0.08896677608385663\n",
      "step =  9000 loss value =  0.0847190927748569\n",
      "step =  10000 loss value =  0.08086061637156261\n",
      "step =  11000 loss value =  0.07733920237919427\n",
      "step =  12000 loss value =  0.0741118366806432\n",
      "step =  13000 loss value =  0.07114267544831922\n",
      "step =  14000 loss value =  0.06840157946386861\n",
      "step =  15000 loss value =  0.06586300075713776\n",
      "step =  16000 loss value =  0.06350512493605955\n",
      "step =  17000 loss value =  0.061309202135547844\n",
      "step =  18000 loss value =  0.059259019161046464\n",
      "step =  19000 loss value =  0.05734047873599764\n",
      "step =  20000 loss value =  0.055541260974993525\n",
      "step =  21000 loss value =  0.053850548678642446\n",
      "step =  22000 loss value =  0.05225880266391867\n",
      "step =  23000 loss value =  0.05075757668445675\n",
      "step =  24000 loss value =  0.04933936394307939\n",
      "step =  25000 loss value =  0.04799746901256813\n",
      "step =  26000 loss value =  0.04672590034082903\n",
      "step =  27000 loss value =  0.045519279545378856\n",
      "step =  28000 loss value =  0.04437276448888385\n",
      "step =  29000 loss value =  0.04328198373303178\n",
      "step =  30000 loss value =  0.042242980439603756\n",
      "step =  31000 loss value =  0.041252164155826936\n",
      "step =  32000 loss value =  0.04030626921222998\n",
      "step =  33000 loss value =  0.03940231869186801\n",
      "step =  34000 loss value =  0.038537593114479345\n",
      "step =  35000 loss value =  0.037709603126952415\n",
      "step =  36000 loss value =  0.03691606561172474\n",
      "step =  37000 loss value =  0.036154882721800605\n",
      "step =  38000 loss value =  0.035424123430612485\n",
      "step =  39000 loss value =  0.034722007250271136\n",
      "step =  40000 loss value =  0.03404688982541596\n",
      "step =  41000 loss value =  0.033397250154433816\n",
      "step =  42000 loss value =  0.032771679226836714\n",
      "step =  43000 loss value =  0.03216886989644056\n",
      "step =  44000 loss value =  0.03158760783587325\n",
      "step =  45000 loss value =  0.031026763439725213\n",
      "step =  46000 loss value =  0.030485284561924352\n",
      "step =  47000 loss value =  0.029962189988626747\n",
      "step =  48000 loss value =  0.029456563560858122\n",
      "step =  49000 loss value =  0.0289675488726039\n",
      "step =  50000 loss value =  0.0284943444795345\n",
      "step =  51000 loss value =  0.02803619956184035\n",
      "step =  52000 loss value =  0.027592409991549608\n",
      "step =  53000 loss value =  0.027162314761105814\n",
      "step =  54000 loss value =  0.026745292734885098\n",
      "step =  55000 loss value =  0.02634075969010224\n",
      "step =  56000 loss value =  0.025948165617473647\n",
      "step =  57000 loss value =  0.0255669922553192\n",
      "step =  58000 loss value =  0.025196750833924007\n",
      "step =  59000 loss value =  0.024836980009496853\n",
      "step =  60000 loss value =  0.024487243969397266\n",
      "step =  61000 loss value =  0.02414713069226294\n",
      "step =  62000 loss value =  0.02381625034846167\n",
      "step =  63000 loss value =  0.023494233827828198\n",
      "step =  64000 loss value =  0.023180731383066422\n",
      "step =  65000 loss value =  0.022875411378257333\n",
      "step =  66000 loss value =  0.022577959133183115\n",
      "step =  67000 loss value =  0.022288075854964076\n",
      "step =  68000 loss value =  0.022005477649425263\n",
      "step =  69000 loss value =  0.02172989460532653\n",
      "step =  70000 loss value =  0.0214610699452909\n",
      "step =  71000 loss value =  0.02119875923777893\n",
      "step =  72000 loss value =  0.020942729665114682\n",
      "step =  73000 loss value =  0.020692759342935456\n",
      "step =  74000 loss value =  0.020448636686900286\n",
      "step =  75000 loss value =  0.020210159822854335\n",
      "step =  76000 loss value =  0.01997713603705095\n",
      "step =  77000 loss value =  0.019749381263287808\n",
      "step =  78000 loss value =  0.019526719604050786\n",
      "step =  79000 loss value =  0.019308982883134367\n",
      "step =  80000 loss value =  0.01909601022726929\n",
      "step =  81000 loss value =  0.018887647674706156\n",
      "step =  82000 loss value =  0.018683747808605797\n",
      "step =  83000 loss value =  0.018484169413543344\n",
      "step =  84000 loss value =  0.018288777153385498\n",
      "step =  85000 loss value =  0.01809744126901338\n",
      "step =  86000 loss value =  0.017910037294483143\n",
      "step =  87000 loss value =  0.017726445790335246\n",
      "step =  88000 loss value =  0.017546552092855633\n",
      "step =  89000 loss value =  0.01737024607815818\n",
      "step =  90000 loss value =  0.017197421940126013\n",
      "step =  91000 loss value =  0.01702797798121703\n",
      "step =  92000 loss value =  0.016861816415326688\n",
      "step =  93000 loss value =  0.016698843181867724\n",
      "step =  94000 loss value =  0.01653896777034887\n",
      "step =  95000 loss value =  0.016382103054749256\n",
      "step =  96000 loss value =  0.016228165137075305\n",
      "step =  97000 loss value =  0.01607707319951611\n",
      "step =  98000 loss value =  0.01592874936462291\n",
      "step =  99000 loss value =  0.015783118563034666\n",
      "step =  100000 loss value =  0.015640108408272194\n",
      "\n",
      "Elapsed Time =>  0:00:36.300226\n"
     ]
    }
   ],
   "source": [
    "obj7 = ClassificationTest(x_data, t_data, 1e-1, 100001)\n",
    "obj7.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.51950518]), 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj7.predict(np.array([13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj7.display_lossval_trend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
