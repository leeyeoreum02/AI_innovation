{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diabetes:\n",
    "    def __init__(self, i_node, h_node, o_node, lr):\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h_node)\n",
    "        self.b2 = np.random.rand(1)\n",
    "        \n",
    "        self.W3 = np.random.rand(h_node, o_node)\n",
    "        self.b3 = np.random.rand(1)\n",
    "        \n",
    "        print(\"========== Diabetes Object is created. ==========\\n\")\n",
    "        \n",
    "    def feed_forward(self, x_data, t_data):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((self.t_data*np.log10(a3 + delta)) + ((1 - self.t_data)*np.log10((1 - a3) + delta)))\n",
    "    \n",
    "    def train(self, x_data, t_data):\n",
    "        self.x_data = x_data\n",
    "        self.t_data = t_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward(self.x_data, self.t_data)\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        z2 = np.dot(test_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        predicted_num = np.argmax(a3)\n",
    "        \n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_xdata)):\n",
    "            predicted_num = self.predict(test_xdata[index])\n",
    "            \n",
    "            if predicted_num == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = len(matched_list) / len(test_xdata)\n",
    "        \n",
    "        return accuracy_val\n",
    "    \n",
    "    def display_lossval_trend(self, loss_val_list, lr, epoch):\n",
    "        plt.title('Loss Value Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(loss_val_list, ls='--', lw=2, label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "        plt.title('Training / Validation Accuracy Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(training_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.plot(validation_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration] loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration] loaded_data.shape =  (759, 9)\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of original data =  0.0 , count =  263\n",
      "[DataGeneration] unique number of original data =  1.0 , count =  496\n",
      "[DataGeneration] unique number of original data =  0.0 , ratio =  34.65  %\n",
      "[DataGeneration] unique number of original data =  1.0 , ratio =  65.35  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of training data =  0.0 , count =  180\n",
      "[DataGeneration] unique number of training data =  1.0 , count =  352\n",
      "[DataGeneration] unique number of training data =  0.0 , ratio =  33.83  %\n",
      "[DataGeneration] unique number of training data =  1.0 , ratio =  66.17  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of test data =  0.0 , count =  83\n",
      "[DataGeneration] unique number of test data =  1.0 , count =  144\n",
      "[DataGeneration] unique number of test data =  0.0 , ratio =  36.56  %\n",
      "[DataGeneration] unique number of test data =  1.0 , ratio =  63.44  %\n",
      "=======================================================================================================\n",
      "generated_training_data.shape =  (532, 9)\n",
      "generated_test_data.shape =  (227, 9)\n"
     ]
    }
   ],
   "source": [
    "seperation_rate = 0.3\n",
    "target_position = -1    # 정답은 마지막 열\n",
    "\n",
    "try:\n",
    "    data_obj = DataGeneration('Diabetes', './diabetes.csv', seperation_rate, target_position)\n",
    "\n",
    "    (generated_training_data, generated_test_data) = data_obj.generate()\n",
    "    \n",
    "    print(\"generated_training_data.shape = \", generated_training_data.shape)\n",
    "    print(\"generated_test_data.shape = \", generated_test_data.shape)\n",
    "\n",
    "except Exception as err:\n",
    "    print('Exception Occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Diabetes Object is created. ==========\n",
      "\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "\n",
      "=========================================================\n",
      "epochs =  0  :  loss value =  0.8665674415211406 \n",
      "\n",
      "epochs =  0  :  training accuracy =  0.34962406015037595\n",
      "epochs =  0  :  validation accuracy =  0.3876651982378855\n",
      "=========================================================\n",
      "epochs =  1  :  loss value =  0.8703452587316409 \n",
      "\n",
      "epochs =  1  :  training accuracy =  0.3966165413533835\n",
      "epochs =  1  :  validation accuracy =  0.4669603524229075\n",
      "=========================================================\n",
      "epochs =  2  :  loss value =  0.8694641307158135 \n",
      "\n",
      "epochs =  2  :  training accuracy =  0.4492481203007519\n",
      "epochs =  2  :  validation accuracy =  0.5066079295154186\n",
      "=========================================================\n",
      "epochs =  3  :  loss value =  0.8610341173934453 \n",
      "\n",
      "epochs =  3  :  training accuracy =  0.5075187969924813\n",
      "epochs =  3  :  validation accuracy =  0.5638766519823789\n",
      "=========================================================\n",
      "epochs =  4  :  loss value =  0.808454215403306 \n",
      "\n",
      "epochs =  4  :  training accuracy =  0.6578947368421053\n",
      "epochs =  4  :  validation accuracy =  0.6740088105726872\n",
      "=========================================================\n",
      "epochs =  5  :  loss value =  0.7381642367253816 \n",
      "\n",
      "epochs =  5  :  training accuracy =  0.7124060150375939\n",
      "epochs =  5  :  validation accuracy =  0.7092511013215859\n",
      "=========================================================\n",
      "epochs =  6  :  loss value =  0.6844720494645741 \n",
      "\n",
      "epochs =  6  :  training accuracy =  0.7030075187969925\n",
      "epochs =  6  :  validation accuracy =  0.7180616740088106\n",
      "=========================================================\n",
      "epochs =  7  :  loss value =  0.643251806975081 \n",
      "\n",
      "epochs =  7  :  training accuracy =  0.6992481203007519\n",
      "epochs =  7  :  validation accuracy =  0.7180616740088106\n",
      "=========================================================\n",
      "epochs =  8  :  loss value =  0.6108584167159785 \n",
      "\n",
      "epochs =  8  :  training accuracy =  0.6842105263157895\n",
      "epochs =  8  :  validation accuracy =  0.7004405286343612\n",
      "=========================================================\n",
      "epochs =  9  :  loss value =  0.5856763647506088 \n",
      "\n",
      "epochs =  9  :  training accuracy =  0.674812030075188\n",
      "epochs =  9  :  validation accuracy =  0.6872246696035242\n",
      "=========================================================\n",
      "epochs =  10  :  loss value =  0.5663548386610009 \n",
      "\n",
      "epochs =  10  :  training accuracy =  0.6597744360902256\n",
      "epochs =  10  :  validation accuracy =  0.6563876651982379\n",
      "=========================================================\n",
      "epochs =  11  :  loss value =  0.5515762395413035 \n",
      "\n",
      "epochs =  11  :  training accuracy =  0.6409774436090225\n",
      "epochs =  11  :  validation accuracy =  0.6299559471365639\n",
      "=========================================================\n",
      "epochs =  12  :  loss value =  0.5401797552089893 \n",
      "\n",
      "epochs =  12  :  training accuracy =  0.6109022556390977\n",
      "epochs =  12  :  validation accuracy =  0.6211453744493393\n",
      "=========================================================\n",
      "epochs =  13  :  loss value =  0.5312292614881178 \n",
      "\n",
      "epochs =  13  :  training accuracy =  0.5902255639097744\n",
      "epochs =  13  :  validation accuracy =  0.6167400881057269\n",
      "=========================================================\n",
      "epochs =  14  :  loss value =  0.5240059606877092 \n",
      "\n",
      "epochs =  14  :  training accuracy =  0.5808270676691729\n",
      "epochs =  14  :  validation accuracy =  0.5991189427312775\n",
      "=========================================================\n",
      "epochs =  15  :  loss value =  0.5179664767930507 \n",
      "\n",
      "epochs =  15  :  training accuracy =  0.5657894736842105\n",
      "epochs =  15  :  validation accuracy =  0.6035242290748899\n",
      "=========================================================\n",
      "epochs =  16  :  loss value =  0.5126973651271518 \n",
      "\n",
      "epochs =  16  :  training accuracy =  0.5676691729323309\n",
      "epochs =  16  :  validation accuracy =  0.5770925110132159\n",
      "=========================================================\n",
      "epochs =  17  :  loss value =  0.5078789647314669 \n",
      "\n",
      "epochs =  17  :  training accuracy =  0.5733082706766918\n",
      "epochs =  17  :  validation accuracy =  0.5638766519823789\n",
      "=========================================================\n",
      "epochs =  18  :  loss value =  0.5032609291394796 \n",
      "\n",
      "epochs =  18  :  training accuracy =  0.5714285714285714\n",
      "epochs =  18  :  validation accuracy =  0.5638766519823789\n",
      "=========================================================\n",
      "epochs =  19  :  loss value =  0.4986476236559598 \n",
      "\n",
      "epochs =  19  :  training accuracy =  0.5714285714285714\n",
      "epochs =  19  :  validation accuracy =  0.5638766519823789\n",
      "=========================================================\n",
      "\n",
      "Elapsed Time =>  0:01:51.470269\n"
     ]
    }
   ],
   "source": [
    "i_node = generated_training_data.shape[1] - 1\n",
    "h_node = 10\n",
    "o_node = 2\n",
    "lr = 1e-1\n",
    "epoch = 20\n",
    "\n",
    "obj1 = Diabetes(i_node, h_node, o_node, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\\n\")\n",
    "\n",
    "#training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "#accuracy(self, test_xdata, test_tdata\n",
    "\n",
    "loss_val_list = []\n",
    "training_acc_list = []\n",
    "validation_acc_list = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epoch):\n",
    "    for index in range(len(generated_training_data)):\n",
    "        input_data = generated_training_data[index, :-1]\n",
    "        target_data = np.zeros(o_nodes) + 0.01\n",
    "        target_data[int(generated_training_data[index, -1])] = 0.99\n",
    "        \n",
    "        obj1.train(input_data, target_data)\n",
    "        \n",
    "    if step % (int)(0.05*epoch) == 0:\n",
    "        cur_loss_val = obj1.loss_val()\n",
    "        print(\"=========================================================\")\n",
    "        print(\"epochs = \", step, \" : \", \"loss value = \", obj1.loss_val(), '\\n')\n",
    "\n",
    "        training_accuracy = obj1.accuracy(generated_training_data[:, 0:-1], generated_training_data[:, -1])\n",
    "        validation_accuracy = obj1.accuracy(generated_test_data[:, 0:-1], generated_test_data[:, -1])\n",
    "        print(\"epochs = \", step, \" : \", \"training accuracy = \", training_accuracy)\n",
    "        print(\"epochs = \", step, \" : \", \"validation accuracy = \", validation_accuracy)\n",
    "        \n",
    "        loss_val_list.append(cur_loss_val)\n",
    "        training_acc_list.append(training_accuracy)\n",
    "        validation_acc_list.append(validation_accuracy)\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1.display_lossval_trend(loss_val_list, lr, epoch)\n",
    "obj1.training_validation_accuracy_trend(training_acc_list, validation_acc_list, lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    input_data = generated_test_data[:, 0:-1]\n",
    "    target_data = generated_test_data[:, [-1]]\n",
    "\n",
    "    accuracy_ret = obj1.accuracy(input_data, target_data)\n",
    "    \n",
    "    print('Accuracy => ', accuracy_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
