{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backpropagation_CE:\n",
    "    def __init__(self, i_node, h1_node, o_node, lr):\n",
    "        self.learning_rate = np.array(lr, ndmin=2)\n",
    "        \n",
    "        self.W2 = np.random.rand(i_node, h1_node)\n",
    "        self.b2 = np.random.rand(1)\n",
    "        \n",
    "        self.W3 = np.random.rand(h1_node, o_node)\n",
    "        self.b3 = np.random.rand(1)\n",
    "        \n",
    "        print(\"========== Backpropagation Object is created. ==========\\n\")\n",
    "        \n",
    "    def feed_forward(self, x_data, t_data):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((t_data*np.log10(a3 + delta)) + ((1 - t_data)*np.log10((1 - a3) + delta)))\n",
    "\n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(x_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum((t_data*np.log10(a3 + delta)) + ((1 - t_data)*np.log10((1 - a3) + delta)))\n",
    "    \n",
    "    def train(self, x_data, t_data):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(x_data, self.W2) + self.b2\n",
    "        a2 = np.array(sigmoid(z2), ndmin=2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = np.array(sigmoid(z3), ndmin=2)\n",
    "        \n",
    "        loss_3 = np.array((a3 - t_data) * a3*(1-a3), ndmin=2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * np.dot(a2.T, loss_3)\n",
    "        self.b3 -= self.learning_rate * loss_3\n",
    "        \n",
    "        loss_2 = np.array(np.dot(loss_3, W3.T) * a2(1-a2), ndmin=2)\n",
    "        \n",
    "        self.W2 -= self.learning_rate * np.dot(x_data.T, loss_2)\n",
    "        self.b2 -= self.learning_rate * loss_2\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        z2 = np.dot(test_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        a3 = sigmoid(z3)\n",
    "        \n",
    "        predicted_num = np.argmax(a3)\n",
    "        \n",
    "        return predicted_num\n",
    "    \n",
    "    def accuracy(self, test_xdata, test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_xdata)):\n",
    "            predicted_num = self.predict(test_xdata[index])\n",
    "            \n",
    "            if predicted_num == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_val = len(matched_list) / len(test_xdata)\n",
    "        \n",
    "        return accuracy_val\n",
    "    \n",
    "    def display_lossval_trend(self, loss_val_list, lr, epoch):\n",
    "        plt.title('Loss Value Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(loss_val_list, ls='--', lw=2, label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    def training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "        plt.title('Training / Validation Accuracy Trend')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid()\n",
    "\n",
    "        plt.plot(training_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.plot(validation_acc, ls='--', label='lr={}, epoch={}'.format(lr, epoch))\n",
    "        plt.legend(loc='best')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration:\n",
    "    \n",
    "    # target_position = 0 (첫번째열이 정답데이터), target_position=-1 (마지막열이 정답데이터)\n",
    "    def __init__(self, name, file_path, seperation_rate, target_position=-1):\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.seperation_rate = seperation_rate\n",
    "        \n",
    "        if (target_position == -1  or  target_position == 0):      \n",
    "            self.target_position = target_position\n",
    "        \n",
    "        else:\n",
    "            err_str = 'target_position must be -1 or 0'            \n",
    "            raise Exception(err_str)    \n",
    "            \n",
    "    \n",
    "    # print data target distribution \n",
    "    # str_of_kind : 'original data' or  'training data'  or  'test data'\n",
    "    def __display_target_distribution(self, data, str_of_kind='original data'):\n",
    "        \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        target_data = data[ :, self.target_position ]\n",
    "        \n",
    "        # numpy.unique() 사용하여 loaded data target 분포 확인\n",
    "        unique, counts = np.unique(target_data, return_counts=True)\n",
    "\n",
    "        unique_target = []\n",
    "    \n",
    "        for index in range(len(unique)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique[index], ', count = ', counts[index])\n",
    "        \n",
    "            unique_target.append(unique[index])\n",
    "\n",
    "        for index in range(len(unique_target)):\n",
    "        \n",
    "            print('[DataGeneration] unique number of ' + str_of_kind + ' = ', unique_target[index], ', ratio = ', np.round(100 * counts[index] / (target_data.shape[0]), 2), ' %')\n",
    "    \n",
    "        print('=======================================================================================================')\n",
    "        \n",
    "        \n",
    "    # numpy.random.shuffle()  이용하여 training_data / test_data 생성\n",
    "    def generate(self):\n",
    "    \n",
    "        # 데이터 불러오기, 파일이 없는 경우 exception 발생\n",
    "\n",
    "        try:\n",
    "            loaded_data = np.loadtxt(self.file_path, delimiter=',', dtype=np.float32)\n",
    "            \n",
    "        except Exception as err:\n",
    "            print('[DataGeneration::generate()]  ', str(err))\n",
    "            raise Exception(str(err))\n",
    "\n",
    "        print(\"[DataGeneration] loaded_data.shape = \", loaded_data.shape)\n",
    "            \n",
    "        # print the target distribution of original data \n",
    "        \n",
    "        self.__display_target_distribution(loaded_data, 'original data')\n",
    "        \n",
    "        \n",
    "        # 분리비율에 맞게 테스트데이터로 분리\n",
    "        total_data_num = len(loaded_data)\n",
    "        test_data_num = int(len(loaded_data) * self.seperation_rate)\n",
    "\n",
    "        # numpy.random.shuffle 을 이용하여 랜덤하게 데이터 섞기\n",
    "        np.random.shuffle(loaded_data)\n",
    "        \n",
    "        # test_data 는 0 : test_data_num\n",
    "        \n",
    "        \n",
    "        test_data = loaded_data[ 0:test_data_num ]\n",
    "\n",
    "        # training_data 는 test_data_num 부터 끝까지 \n",
    "        training_data = loaded_data[ test_data_num: ]\n",
    "\n",
    "        # display target distribution of generated data \n",
    "        \n",
    "        self.__display_target_distribution(training_data, 'training data')\n",
    "        \n",
    "        self.__display_target_distribution(test_data, 'test data')\n",
    "        \n",
    "        return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataGeneration] loaded_data.shape =  (759, 9)\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of original data =  0.0 , count =  263\n",
      "[DataGeneration] unique number of original data =  1.0 , count =  496\n",
      "[DataGeneration] unique number of original data =  0.0 , ratio =  34.65  %\n",
      "[DataGeneration] unique number of original data =  1.0 , ratio =  65.35  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of training data =  0.0 , count =  180\n",
      "[DataGeneration] unique number of training data =  1.0 , count =  352\n",
      "[DataGeneration] unique number of training data =  0.0 , ratio =  33.83  %\n",
      "[DataGeneration] unique number of training data =  1.0 , ratio =  66.17  %\n",
      "=======================================================================================================\n",
      "=======================================================================================================\n",
      "[DataGeneration] unique number of test data =  0.0 , count =  83\n",
      "[DataGeneration] unique number of test data =  1.0 , count =  144\n",
      "[DataGeneration] unique number of test data =  0.0 , ratio =  36.56  %\n",
      "[DataGeneration] unique number of test data =  1.0 , ratio =  63.44  %\n",
      "=======================================================================================================\n",
      "generated_training_data.shape =  (532, 9)\n",
      "generated_test_data.shape =  (227, 9)\n"
     ]
    }
   ],
   "source": [
    "seperation_rate = 0.3\n",
    "target_position = -1    # 정답은 마지막 열\n",
    "\n",
    "try:\n",
    "    data_obj = DataGeneration('Diabetes', '../diabetes.csv', seperation_rate, target_position)\n",
    "\n",
    "    (generated_training_data, generated_test_data) = data_obj.generate()\n",
    "    \n",
    "    print(\"generated_training_data.shape = \", generated_training_data.shape)\n",
    "    print(\"generated_test_data.shape = \", generated_test_data.shape)\n",
    "\n",
    "except Exception as err:\n",
    "    print('Exception Occur !!')\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Backpropagation Object is created. ==========\n",
      "\n",
      "Neural Network Learning using Backpropagation...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (1,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b0dc8c3ffed4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mobj1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-7ed5450ce5f6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_data, t_data)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb3\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mloss_3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mloss_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (1,2)"
     ]
    }
   ],
   "source": [
    "i_node = generated_training_data.shape[1] - 1\n",
    "h1_node = 10\n",
    "o_node = 2\n",
    "lr = 1e-1\n",
    "epoch = 20\n",
    "\n",
    "obj1 = Backpropagation_CE(i_node, h1_node, o_node, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Backpropagation...\\n\")\n",
    "\n",
    "#training_validation_accuracy_trend(self, training_acc, validation_acc, lr, epoch):\n",
    "#accuracy(self, test_xdata, test_tdata\n",
    "\n",
    "loss_val_list = []\n",
    "training_acc_list = []\n",
    "validation_acc_list = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epoch):\n",
    "    for index in range(len(generated_training_data)):\n",
    "        input_data = np.array(generated_training_data[index, :-1], ndmin=2)\n",
    "        target_data = np.zeros(o_node) + 0.01\n",
    "        target_data[int(generated_training_data[index, -1])] = 0.99\n",
    "        target_data = np.array(target_data, ndmin=2)\n",
    "        \n",
    "        obj1.train(input_data, target_data)\n",
    "        \n",
    "    if step % (int)(0.05*epoch) == 0:\n",
    "        cur_loss_val = obj1.loss_val()\n",
    "        print(\"=========================================================\")\n",
    "        print(\"epochs = \", step, \" : \", \"loss value = \", obj1.loss_val(), '\\n')\n",
    "\n",
    "        training_accuracy = obj1.accuracy(generated_training_data[:, 0:-1], generated_training_data[:, -1])\n",
    "        validation_accuracy = obj1.accuracy(generated_test_data[:, 0:-1], generated_test_data[:, -1])\n",
    "        print(\"epochs = \", step, \" : \", \"training accuracy = \", training_accuracy)\n",
    "        print(\"epochs = \", step, \" : \", \"validation accuracy = \", validation_accuracy)\n",
    "        \n",
    "        loss_val_list.append(cur_loss_val)\n",
    "        training_acc_list.append(training_accuracy)\n",
    "        validation_acc_list.append(validation_accuracy)\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"=========================================================\")\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj1.display_lossval_trend(loss_val_list, lr, epoch)\n",
    "obj1.training_validation_accuracy_trend(training_acc_list, validation_acc_list, lr, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    input_data = generated_test_data[:, 0:-1]\n",
    "    target_data = generated_test_data[:, [-1]]\n",
    "\n",
    "    accuracy_ret = obj1.accuracy(input_data, target_data)\n",
    "    \n",
    "    print('Accuracy => ', accuracy_ret)\n",
    "    \n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99, 0.01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
